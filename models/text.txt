https://www.comp.nus.edu.sg/images/resources/content/undergraduates/FYP-Report-Format-final_000.pdf
Abstract
The use of deep learning to enhance human lives has become more and more popular due to its high performance. One implementation is to help monitoring the activities of elderly patients. By using deep learning, It is possible to detect and classify human activities from sensors placed on human body. Some research papers have reported success in doing the classification. There are some challenges, that the sensor cannot be too intrusive. We don’t want to burden the elderly patients. Only limited data can be generated from accelerometer at wrist and also from phone. In addition, we want to classify multiple activities in one go. Concurrent activity recognition is a novel field in the activity recognition domain. Two methods are tried out, out of all papers, namely Japanese Paper and “Deep convolutional neural networks on multichannel time series for human activity recognition”. The models taken out from the paper are tried to be implemented with some modifications, and the result is attached. Overall, the performance manages to be quite comparable even though features used are much lesser.

Acknowledgement
The author would like to thank Arinta Pratiwi for her unwavering support throughout these difficult times. This project will never be finished without her constant reminder and the weekend Don’t Starve Together gaming session.

Introduction
Automatically recognizing human’s physical activities (a.k.a. human activity recognition or HAR) has emerged as a key problem to ubiquitous computing, human-computer interaction and human behavior analysis [Bulling et al., 2014; Pl¨atz et al., 2012; Reddy et al., 2010]. In this problem, human’s activity is recognized based upon the signals acquired (in real time) from multiple body-worn (or body-embedded) inertial sensors. For HAR, signals acquired by on-body sensors are arguably favorable over the signals acquired by video cameras, due to the following reasons: i) on-body sensors alleviate the limitations of environment constraints and stationary settings that cameras often suffer from [Bulling et al., 2014; Ji et al., 2010; Le et al., 2011]; ii) multiple on-body sensors allow more accurate and more effective deployment of signal acquisition on human body; iii) on-body sensors enjoy the merits on information privacy, as their acquired signals are target-specific while the signals acquired by camera may also contain the information of other nontarget subjects in the scene. In the past few years, body-worn based HAR made promising applications, e.g. game consoles, personal fitness training, medication intake and health monitoring. An excellent survey on this topic can be found at [Bulling et al., 2014]. The key factor attributed to the success of a HAR system is to find an effective representation of the time series collected from the on-body sensors. Though considerable research efforts have been made to investigate this issue, diminishing returns occurred. Conventionally, the HAR problem is often taken as one of specific applications of time series analysis. The widely-used features in HAR include basis transform coding (e.g. signals with wavelet transform and Fourier transform) [Huynh and Schiele, 2005], statistics of raw signals (e.g, mean and variance of time sequences) [Bulling et al., 2014] and symbolic representation [Lin et al., 2003]. Although these features are widely used in many time series problems, they are heuristic and not task-dependent. It is worth noting that the HAR task has its own challenges, such as intraclass variability, interclass similarity, the NULL-class dominance, and complexness and diversity of physical activities [Bulling et al., 2014]. All these challenges make it highly desirable to develop a systematical feature representation approach to effectively characterize the nature of signals relative to the activity recognition task. Recently, deep learning has emerged as a family of learning models that aim to model high-level abstractions in data [Bengio, 2009; Deng, 2014]. In deep learning, a deep architecture with multiple layers is built up for automating feature design. Specifically, each layer in deep architecture performs a nonlinear transformation on the outputs of the previous layer, so that through the deep learning models the data are represented by a hierarchy of features from low-level to high-level. The well-known deep learning models include convolutional neural network, deep belief network and autoencoders. Depending on the usage of label information, the deep learning models can be learned in either supervised or unsupervised manner. Though deep learning models achieve remarkable results in computer vision, natural language processing, and speech recognition, it has not been fully exploited in the field Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (IJCAI 2015) 3995 of HAR. In this paper, we tackle the HAR problem by adapting one particular deep learning model —- the convolutional neural networks (CNN). The key attribute of the CNN is conducting different processing units (e.g. convolution, pooling, sigmoid/ hyperbolic tangent squashing, rectifier and normalization ) alternatively. Such a variety of processing units can yield an effective representation of local salience of the signals. Then, the deep architecture allows multiple layers of these processing units to be stacked, so that this deep learning model can characterize the salience of signals in different scales. Therefore, the features extracted by the CNN are task dependent and non-handcrafted. Moreover, these features also own more discriminative power, since the CNN can be learned under the supervision of output labels. All these advantages of the CNN will be further elaborated in the following sections. As detailed in the following sections, in the application on HAR, the convolution and pooling filters in the CNN are applied along the temporal dimension for each sensor, and all these feature maps for different sensors need to be unified as a common input for the neural network classifier. Therefore, a new architecture of the CNN is developed in this paper. In the experiments, we performed an extensive study on the comparison between the proposed method and the stateof- the-art methods on benchmark datasets. The results show that the proposed method is a very competitive algorithm for the HAR problems. We also investigate the efficiency of the CNN, and conclude that the CNN is fast enough for online human activity recognition.
A case in point, which motivates our work in this paper, is the tri-axial accelerometer data collected in-the-wild for daily human activity detection. The ExtraSensory dataset [6] that captures such data, for instance, has up to 2,000 classes of human activities. Each activity can further generate multiple patterns of movement, leading to different patterns in the time-series data.
The rest of the paper is organized as follows. Section II discusses the existing works related to change point detection in time series. Section III formally defines the problem of change point detection. Section IV describes Shape-CD and the conditional neural field model that it uses. This section is followed by the detailed evaluation of our approach in Section V on four real-world datasets to illustrate its performance in terms of both accuracy and speed. We also perform a parameter sensitivity analysis to understand the effect of different parameter setting on our model’s performance. We conclude the paper in Section VI.
Recently, DeepSense model [6] and Deep convolutional LSTM model [3] propose a deep learning architecture for activity recognition. By reducing the dimensionality of the sensor outputs in the form of representation using Convolutional Neural Networks (CNN), it classifies the signal pattern by Recurrent Neural Networks (RNN). This paper focuses on the problem that these architectures [6, 3] as well as most of other architectures (the semi-CRF model [5] and the Bayesian model using the importance sampling [1]) recognize one activity at a time. We propose an algorithm which recognizes multiple overlapping activities.
Look from ‘Coveted Projects!
Study of Existing Methods (Literature Review)
A couple of paper I read. Use it.
Methodology
Results and Discussion
Conclusion
