{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNNLSTM-2Layers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c47008de34d44c5997561c6b3a96c5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0ceb95f932d44ac59306c6d952de2cec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0298ac1555754072943176bfc4bea451",
              "IPY_MODEL_afb2ad554ff44329834371534bf14e66"
            ]
          }
        },
        "0ceb95f932d44ac59306c6d952de2cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0298ac1555754072943176bfc4bea451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da619adc2d1f43ea9cd200827459cc05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch: 1 / 10",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ece04b5af508420897dcdd1bc94768a7"
          }
        },
        "afb2ad554ff44329834371534bf14e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78d8c1316ad44deb9c06abde0a2d6241",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c31506c7af5f4ab688ce28ba28ae660d"
          }
        },
        "da619adc2d1f43ea9cd200827459cc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ece04b5af508420897dcdd1bc94768a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78d8c1316ad44deb9c06abde0a2d6241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c31506c7af5f4ab688ce28ba28ae660d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99c64156779342b39bad78d14c13686a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4aa60eeee044e4fa329b5d0dd70a665",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce76a8f16b144eb8b8683932e37db1f9",
              "IPY_MODEL_cad57b63315746f79d2c8ecc0b4dcf30"
            ]
          }
        },
        "c4aa60eeee044e4fa329b5d0dd70a665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce76a8f16b144eb8b8683932e37db1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97d6c21a58a94e1ba4946789c9efa451",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Testing: 13 / 253",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d0e7c9b85184b54a291f6fd8bcf5a50"
          }
        },
        "cad57b63315746f79d2c8ecc0b4dcf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4cfe229ca1664515a15133fcc5519457",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 253,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_beb261771e8640d8aab048e48da4ec47"
          }
        },
        "97d6c21a58a94e1ba4946789c9efa451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d0e7c9b85184b54a291f6fd8bcf5a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cfe229ca1664515a15133fcc5519457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "beb261771e8640d8aab048e48da4ec47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ghifarahadian/concurrent-activity-recognition/blob/master/CNNLSTM_2Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p72HxINZnbFc"
      },
      "source": [
        "IS_COLAB = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTIJjcyZ80g",
        "outputId": "e34be8c8-c565-4f04-c80f-89f750a13baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "# Log progress\n",
        "def log_progress(sequence, every=None, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "if IS_COLAB:\n",
        "    # using google colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    ROOT = os.path.join('/content', 'drive', 'My Drive',\n",
        "                        'concurrent-activity-recognition')\n",
        "    os.chdir(ROOT)\n",
        "else:\n",
        "    # using own pc\n",
        "    ROOT = os.path.join(os.getcwd(), 'concurrent-activity-recognition')\n",
        "    os.chdir(ROOT)\n",
        "\n",
        "print(ROOT)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/concurrent-activity-recognition\n",
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_oOhST5RNtK"
      },
      "source": [
        "class OpportunityDatasetParsed(Dataset):\n",
        "    def __init__(self, filenames):\n",
        "        self.filenames = filenames\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        print(filename)\n",
        "\n",
        "        df = pd.read_csv(filename, header = 0)\n",
        "\n",
        "        # first 15 columns are for data\n",
        "        data = torch.FloatTensor(\n",
        "            df.iloc[:, 0:15].values.astype('float'))\n",
        "                \n",
        "        # last 3 columns are for label\n",
        "        label = torch.FloatTensor(\n",
        "            df.iloc[29, 15:18].values.astype('float'))\n",
        "\n",
        "        return data, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaJxhUtfaLVR",
        "outputId": "78660f31-33b6-452e-dc46-26fdd221f740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# grid search\n",
        "conv1_outchs = [20]\n",
        "conv1_sizes = [3]\n",
        "conv2_outchs = [40]\n",
        "conv2_sizes = [3]\n",
        "lstm1_hs = [20]\n",
        "learning_rates = [0.001]\n",
        "\n",
        "grids = [(conv1_outch, conv1_size, conv2_outch,\n",
        "         conv2_size, lstm1_h, learning_rate)\n",
        "        for conv1_outch in conv1_outchs\n",
        "        for conv1_size in conv1_sizes\n",
        "        for conv2_outch in conv2_outchs\n",
        "        for conv2_size in conv2_sizes\n",
        "        for lstm1_h in lstm1_hs\n",
        "        for learning_rate in learning_rates\n",
        "        ]\n",
        "\n",
        "#grids = [(30, 3, 60, 3, 20, 0.1), (20, 3, 60, 3, 30, 0.1)]\n",
        "len(grids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCiwj9_Poakn"
      },
      "source": [
        "# dataset constants\n",
        "data_row_n = 30\n",
        "data_feature_n = 15\n",
        "data_output1_n = 3\n",
        "\n",
        "# training hyperparameter\n",
        "num_epochs = 10\n",
        "batch_size = 1\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, grid):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        conv1_outch = grid[0]\n",
        "        conv1_size = grid[1]\n",
        "        conv1_outlen = data_row_n - (conv1_size - 1)\n",
        "        conv2_outch = grid[2]\n",
        "        conv2_size = grid[3]\n",
        "        conv2_outlen = conv1_outlen - (conv2_size - 1)\n",
        "        lstm1_h = grid[4]\n",
        "        self.lstm1_h = lstm1_h\n",
        "        lstm1_hlen = conv2_outlen\n",
        "        self.lstm1_hlen = lstm1_hlen\n",
        "\n",
        "        self.conv1 = nn.Conv1d(data_feature_n, conv1_outch, conv1_size)\n",
        "        self.conv2 = nn.Conv1d(conv1_outch, conv2_outch, conv2_size)\n",
        "        self.lstm1 = nn.LSTM(conv2_outch, lstm1_h)\n",
        "        self.fc1 = nn.Linear(lstm1_h*lstm1_hlen, data_output1_n)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        batch_len = x.shape[0]\n",
        "        x.transpose_(1, 2)\n",
        "        x = F.relu(self.conv1(x), inplace=False)\n",
        "        x = F.relu(self.conv2(x), inplace=False)\n",
        "        x.transpose_(1, 2)\n",
        "        x, _ = self.lstm1(x, h)\n",
        "        #print(x.shape)\n",
        "        x = x.reshape([batch_len, -1])\n",
        "        #print(x.shape)\n",
        "        out = self.fc1(x)\n",
        "        #print(x.shape)\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(1, self.lstm1_hlen,\n",
        "                             self.lstm1_h).zero_().to(device),\n",
        "                  weight.new(1, self.lstm1_hlen,\n",
        "                             self.lstm1_h).zero_().to(device))\n",
        "        return hidden\n",
        "\n",
        "# try to use this paper instead lul\n",
        "class CNN_Custom(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Custom, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 50, (1, 5))\n",
        "        self.pool1 = nn.MaxPool2d((1, 2))\n",
        "        self.conv2 = nn.Conv2d(50, 40, (1, 5))\n",
        "        self.pool2 = nn.MaxPool2d((1, 3))\n",
        "        self.conv3 = nn.Conv2d(40, 20, (1, 3))\n",
        "        self.fc1 = nn.Linear(300, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_len = x.shape[0]\n",
        "        #print(x.shape)\n",
        "        x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
        "        #print(x.shape)\n",
        "        x.transpose_(2, 3)\n",
        "        for p in self.conv1.parameters():\n",
        "            if p.requires_grad:\n",
        "                print(p.name, p.data)\n",
        "        #print(.parameters().data)\n",
        "        print(x)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        print(x)\n",
        "        x = self.pool1(x)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(x)\n",
        "        x = self.pool2(x)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(x)\n",
        "        x = x.reshape([batch_len, -1])\n",
        "        #print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        #print(x.shape)\n",
        "        return x\n",
        "\n",
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    def train_step(data, labels):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "        data = torch.reshape(data, (len(labels), -1, 15))\n",
        "\n",
        "        label1 = torch.reshape(labels[:, 0:1].long(), (-1,))\n",
        "        \n",
        "        output1 = model(data)\n",
        "\n",
        "        loss = loss_function(output1, label1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    return train_step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A7WrSAHwFt0",
        "outputId": "995cbf75-a91e-49ea-9576-c33b837cd0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c47008de34d44c5997561c6b3a96c5ad",
            "0ceb95f932d44ac59306c6d952de2cec",
            "0298ac1555754072943176bfc4bea451",
            "afb2ad554ff44329834371534bf14e66",
            "da619adc2d1f43ea9cd200827459cc05",
            "ece04b5af508420897dcdd1bc94768a7",
            "78d8c1316ad44deb9c06abde0a2d6241",
            "c31506c7af5f4ab688ce28ba28ae660d"
          ]
        }
      },
      "source": [
        "# Training and validation, by using grid search\n",
        "torch.manual_seed(69)\n",
        "models = []\n",
        "fig, axs = plt.subplots(len(grids), figsize=(18, 4*len(grids)))\n",
        "i = 0\n",
        "for grid in grids:\n",
        "    #model = CNN_LSTM(grid).to(device)\n",
        "    model = CNN_Custom().to(device)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=grid[5])\n",
        "    train_step = make_train_step(model, loss_function, optimizer)\n",
        "\n",
        "    data_train_files = glob.glob(\"dataset_parsed/train/*.csv\")\n",
        "    #h = model.init_hidden()\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    # TODO: Need to do the splitting better\n",
        "    data_train = OpportunityDatasetParsed(data_train_files)\n",
        "    train_dataset, val_dataset = random_split(data_train,\n",
        "            [math.ceil(0.8*len(data_train)), math.floor(0.2*len(data_train))])\n",
        "\n",
        "    for epoch in log_progress(range(num_epochs), name=\"Epoch\"):\n",
        "    #for epoch in range(num_epochs):\n",
        "        #print(\"Epoch \" + str(epoch + 1))\n",
        "\n",
        "        dataloader_train = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "        train_losses_temp = []\n",
        "        #for data, labels in log_progress(dataloader_train, name=\"Training\"):\n",
        "        for data, labels in dataloader_train:\n",
        "            loss = train_step(data, labels)\n",
        "            #print(loss)\n",
        "            train_losses_temp.append(loss)\n",
        "\n",
        "        train_losses.append(np.mean(train_losses_temp))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dataloader_val = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                            shuffle=False)\n",
        "            \n",
        "            val_losses_temp = []\n",
        "            for data, labels in dataloader_val:\n",
        "                model.eval()\n",
        "                data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "                label1 = torch.reshape(labels[:, 0:1].long(), (-1,))\n",
        "\n",
        "                output1 = model(data)\n",
        "                #print(output1)\n",
        "\n",
        "                val_loss = loss_function(output1, label1)\n",
        "                val_losses_temp.append(val_loss.item())\n",
        "            \n",
        "            val_losses.append(np.mean(val_losses_temp))\n",
        "\n",
        "    models.append(model)\n",
        "\n",
        "    try:\n",
        "        axs[i].plot(range(0, num_epochs), train_losses, label=\"train_loss\")\n",
        "        axs[i].plot(range(0, num_epochs), val_losses, label=\"val_loss\")\n",
        "        axs[i].set_title(grid)\n",
        "    except:\n",
        "        axs.plot(range(0, num_epochs), train_losses, label=\"train_loss\")\n",
        "        axs.plot(range(0, num_epochs), val_losses, label=\"val_loss\")\n",
        "        axs.set_title(grid)\n",
        "    i += 1\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c47008de34d44c5997561c6b3a96c5ad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(HTML(value=''), IntProgress(value=0, max=10)))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "            7.7551e-01, -6.2765e-01,  2.0680e+00,  1.8819e+00,  2.7118e+00],\n",
            "          [ 2.6790e+00,  1.8763e+00,  1.5156e+00,  1.3962e+00,  1.2409e+00,\n",
            "            1.0641e+00,  7.6553e-01,  3.7616e-01,  2.4238e-01, -1.2310e-01,\n",
            "           -4.8859e-01, -5.0531e-01, -8.4691e-01, -1.3223e+00, -1.2411e+00,\n",
            "           -1.0213e+00, -9.6635e-01, -1.0117e+00, -6.4625e-01, -3.8348e-01,\n",
            "           -3.6198e-01, -1.2721e+00,  3.5036e-03, -1.8521e-01,  6.8001e-02,\n",
            "           -3.6628e-03,  2.3044e-01, -7.8002e-01, -4.1884e-02, -2.5688e-01]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL1-43.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000, -2.2272, -1.7240, -0.4345,\n",
            "            0.3360,  1.0279,  1.7670, -0.1672, -0.6389, -0.4660,  0.7606,\n",
            "            0.3675, -0.4031, -0.6232, -0.3087, -0.0886,  1.2638,  0.8864,\n",
            "            1.0279, -0.3559],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000, -1.2405, -1.4035, -1.1152,\n",
            "           -0.9647, -0.0244,  0.3768,  1.6180,  1.2669, -1.2155,  0.5272,\n",
            "            1.1165,  0.6651,  0.7153,  0.5899,  1.0663,  0.4645, -0.3629,\n",
            "           -1.0525, -1.0274],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.7923,  0.7335,  0.8772,\n",
            "            1.2233,  1.5891,  1.1058,  1.3670, -0.0632,  0.5049,  0.2959,\n",
            "           -0.4551, -0.5988, -0.9449, -1.0755, -1.3498, -1.3041, -0.8861,\n",
            "           -0.7620, -1.0494],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.8559,  0.7935,  0.7647,\n",
            "            0.6782,  0.3470,  0.8127,  1.1488, -0.0852,  0.3950,  1.1199,\n",
            "            0.4814,  0.0253, -0.9590, -1.5831, -1.5975, -1.5207, -1.3287,\n",
            "           -1.1030,  0.7551],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000, -0.2448,  0.1853,  0.2394,\n",
            "           -0.0682,  0.4559,  1.5356,  2.0598,  1.3846,  1.1425,  0.4873,\n",
            "           -0.1480, -0.4528, -0.8488, -1.0624, -1.1479, -1.4498, -1.3216,\n",
            "           -0.5383, -0.2078],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.6673,  0.3607, -0.2784,\n",
            "            0.4802,  0.9842,  0.8283, -1.1565, -1.7176, -1.9930, -1.5669,\n",
            "           -0.3823, -0.6161,  0.0645,  0.7244,  0.8439,  1.0154,  1.2388,\n",
            "            0.6309, -0.1277],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000, -1.2563, -2.1834, -2.0201,\n",
            "           -0.9356, -0.3468, -0.4459, -0.0494,  0.2538,  1.3382,  0.9476,\n",
            "            1.0117,  0.7960,  0.6036,  0.6269,  0.3587,  0.0614, -0.1019,\n",
            "            0.3820,  0.9593],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  1.0449,  1.1203,  1.2397,\n",
            "            0.9947,  0.3915,  0.8313,  0.7182,  0.5297,  0.0648,  0.3224,\n",
            "            0.5046,  0.1339, -0.4190, -0.5446, -0.5886, -1.2860, -1.4933,\n",
            "           -1.6253, -1.9394],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.2735,  0.2024, -0.2240,\n",
            "            0.3682, -0.4530, -0.6505,  1.4659,  1.3712,  0.8737,  1.0158,\n",
            "            0.9842,  0.5578, -0.2161,  0.5104, -1.3059, -0.6820, -0.7531,\n",
            "           -2.4904, -0.8479],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000, -0.4726, -0.2732, -0.1060,\n",
            "           -0.0674, -0.6784, -0.9807, -0.4790, -0.0545, -1.3087, -1.6045,\n",
            "           -0.7748, -0.1252,  0.7173,  1.5213,  1.9586,  1.5020,  1.2576,\n",
            "            0.5436, -0.5755],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.2163,  0.2555,  0.0857,\n",
            "            0.1118,  0.9783,  1.1873,  1.5051,  1.4833,  1.0349,  0.6996,\n",
            "            0.2207, -0.2626, -0.9114, -1.3990, -1.4948, -1.5296, -1.2031,\n",
            "           -0.6762, -0.3018],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000, -1.0151, -1.2412, -1.0546,\n",
            "           -0.3594, -0.2802, -1.9138, -0.6816,  0.9803,  0.9011,  1.5286,\n",
            "            1.5059,  1.2572,  0.9916, -0.0881, -0.0089,  0.4546,  0.2454,\n",
            "           -0.7098, -0.5120],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.1159,  0.5704,  0.9025,\n",
            "            0.6811,  1.2287,  1.9454,  1.2171,  0.3956,  0.1101, -0.1871,\n",
            "           -0.6299, -0.9620, -1.6436, -1.5912, -1.2125, -0.2104, -0.6881,\n",
            "           -0.6765,  0.6345],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  1.5383,  1.6130,  0.8913,\n",
            "            0.2692,  0.9162,  1.0157, -0.1415, -0.0419,  1.2397, -0.0544,\n",
            "           -0.6392, -1.1867,  0.0701, -1.0000, -0.3157, -0.6267, -0.9378,\n",
            "           -0.5521, -2.0577],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000, -0.2161, -1.3512, -0.6899,\n",
            "           -0.1964, -1.0156, -1.3907, -0.8774,  0.2083, -0.4135,  0.2281,\n",
            "            0.4353,  0.0603, -0.3050,  0.6031, -0.2260, -0.1964,  1.0078,\n",
            "            1.6889,  2.6464]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL1-56.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0911,\n",
            "            0.2182,  0.8729],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1014,\n",
            "           -0.8511, -0.2503],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7044,\n",
            "           -1.1446,  0.4402],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.9785,\n",
            "            1.0202, -0.0416],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.1243,\n",
            "            0.7901,  0.3343],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1205,\n",
            "           -0.9343,  1.0548],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7160,\n",
            "            0.4265, -1.1425],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7735,\n",
            "            0.3558, -1.1292],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.9472,\n",
            "           -0.0984,  1.0456],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.6739,\n",
            "           -0.4751,  1.1490],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4008,\n",
            "           -1.1382,  0.7374],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.5774,\n",
            "            0.5774, -1.1547],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1209,\n",
            "           -0.3203, -0.8006],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1106,\n",
            "            0.9401, -1.0507],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0876,\n",
            "           -0.2079, -0.8797]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL1-143.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -9.2316e-03,  3.0669e-01,  1.9899e-01,  4.5030e-01,\n",
            "            5.4364e-01,  7.8058e-01,  5.2210e-01,  1.1683e+00,  5.4364e-01,\n",
            "            6.0826e-01, -2.1489e+00, -1.8114e+00,  9.1290e-02, -1.2442e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -7.1053e-01, -7.8764e-01, -8.0692e-01, -6.3342e-01,\n",
            "           -5.2739e-01, -4.7919e-01, -1.4183e-01, -9.9006e-01,  2.4373e-01,\n",
            "            1.8052e+00,  2.3161e+00,  4.0759e-01, -3.0569e-01,  6.1001e-01],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  8.2082e-01,  6.9293e-01,  5.2851e-01,  2.2706e-01,\n",
            "            5.4678e-01, -2.1140e-01,  3.3668e-01, -3.0275e-01,  5.0110e-01,\n",
            "           -4.9458e-01, -2.1206e+00, -1.3076e+00,  1.7982e+00, -1.0153e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -1.4665e+00, -1.0340e+00, -1.3275e+00, -9.4126e-01,\n",
            "           -6.6319e-01, -4.6235e-01,  4.7449e-02,  2.6373e-01,  2.7918e-01,\n",
            "            4.1822e-01,  8.8167e-01,  1.2215e+00,  1.4687e+00,  1.3142e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  1.8298e+00,  1.3452e+00,  4.8617e-01, -1.9667e-01,\n",
            "           -1.0998e+00, -1.3861e+00, -1.5183e+00, -9.4560e-01, -1.0856e-01,\n",
            "            8.3861e-01,  2.4387e-01,  1.5734e-03, -1.5262e-01,  6.6239e-01],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  9.2786e-01,  1.0821e+00,  1.6684e+00,  5.5760e-01,\n",
            "            1.2673e+00, -1.5207e-01, -2.7549e-01, -6.7661e-01, -8.0003e-01,\n",
            "           -1.1086e+00,  4.3418e-01, -2.7549e-01, -1.1394e+00, -1.5097e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -9.2825e-01, -1.2670e+00, -4.9462e-01,  5.0817e-01,\n",
            "            2.5070e-01,  2.2359e-01,  1.0773e+00,  2.7780e-01,  1.8294e-01,\n",
            "            2.2698e+00,  2.3714e-01, -1.1044e+00,  2.3714e-01, -1.4703e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -4.6187e-01, -2.4080e-01, -1.0587e+00,  5.1082e-01,\n",
            "            2.0583e+00,  1.5167e+00,  1.1290e-01,  4.3345e-01,  7.8715e-01,\n",
            "           -1.5238e-01, -6.8294e-01, -2.0764e-01, -1.4456e+00, -1.1693e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -3.2239e-01,  1.4012e+00, -8.4823e-01,  1.1237e+00,\n",
            "           -4.8307e-01, -1.6224e+00,  8.7536e-01,  1.6349e+00, -1.1790e-01,\n",
            "            3.2030e-01, -1.4909e+00, -8.8684e-02,  1.4502e-01, -5.2689e-01],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  9.1128e-01,  1.5560e+00,  1.1457e+00,  6.1822e-01,\n",
            "            5.9868e-01,  4.0331e-01,  2.2747e-01,  1.2560e-02, -1.8281e-01,\n",
            "           -3.7819e-01, -3.5865e-01, -1.1011e+00, -1.7653e+00, -1.6872e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  2.0130e+00,  1.7139e+00,  7.7377e-01, -1.6635e-01,\n",
            "           -6.1504e-01, -1.0210e+00, -1.0210e+00, -9.7827e-01, -1.6788e-02,\n",
            "            4.3190e-01, -4.4411e-01, -7.4324e-01, -6.7914e-01,  7.5240e-01],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -1.6290e+00, -9.7586e-01, -9.4864e-01, -1.0847e+00,\n",
            "           -8.1257e-01, -2.4105e-01,  3.3047e-01,  5.4819e-01,  2.2161e-01,\n",
            "            1.3996e-01,  1.0925e+00,  1.1741e+00,  3.3047e-01,  1.8545e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  2.5769e+00,  1.4728e+00,  4.7746e-01,  6.9540e-02,\n",
            "            4.5026e-01, -6.6432e-02, -6.1576e-01, -1.1977e+00, -7.1366e-01,\n",
            "           -3.8733e-01, -2.9487e-01, -6.9734e-01, -7.8981e-01, -2.8399e-01],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  1.1105e+00,  4.3455e-01,  2.9470e-01,  6.2103e-01,\n",
            "           -1.0806e+00, -1.8265e+00, -1.2787e+00,  3.7628e-01,  1.8448e+00,\n",
            "            5.6275e-01,  1.0822e-01,  1.6650e-01, -3.6962e-01, -9.6401e-01],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "            0.0000e+00, -6.4545e-01, -7.5498e-01, -6.3632e-01, -5.0854e-01,\n",
            "            1.3352e+00,  1.8920e+00,  2.0107e+00,  1.1214e-01, -8.0975e-01,\n",
            "            7.5628e-02, -5.7243e-01, -8.2800e-01, -4.6290e-01, -2.0733e-01]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL1-139.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 1.3392,  0.9343,  0.1245, -1.4502, -1.2702, -2.0350, -0.7753,\n",
            "           -1.0453, -0.6404, -1.4952,  0.7993,  0.7543,  1.0243, -1.0903,\n",
            "           -0.6404, -0.3254, -0.5054,  0.0345, -0.7303,  0.9793,  1.1592,\n",
            "            1.2492,  0.6644,  1.9691,  0.7093,  0.7093,  0.1695, -0.1905,\n",
            "           -0.1005, -0.3254],\n",
            "          [ 1.4949,  0.4639, -0.3796, -0.9420, -1.1763, -2.6759, -1.4575,\n",
            "            0.2765,  0.3702, -0.0984, -0.0515,  0.9794,  0.9794, -0.2859,\n",
            "           -0.7545, -0.8014, -0.8014, -0.6608,  0.1359,  0.0422,  0.7920,\n",
            "            1.7293,  1.6824,  1.3075,  0.8389, -0.1921,  0.0890,  0.5577,\n",
            "           -0.6139, -0.8482],\n",
            "          [ 0.0403, -0.5636, -0.3372,  1.0971, -1.2430, -0.2617,  1.5500,\n",
            "            0.4177,  0.1157,  2.4558,  0.7951, -0.7146, -1.1675, -0.7146,\n",
            "           -1.2430, -0.3372, -0.4127,  0.2667, -1.5449, -1.1675,  0.4932,\n",
            "            0.3422,  0.9461, -1.1675, -0.5636, -0.4127,  0.7951, -0.3372,\n",
            "            0.9461,  1.9274],\n",
            "          [-0.5727, -0.4183, -0.1866, -0.7657, -0.9009, -0.6499, -1.4221,\n",
            "           -1.4800, -1.8660, -1.6923, -1.1132, -0.6885, -0.0901,  0.0837,\n",
            "            0.4504,  0.7400,  0.4697, -0.3217, -0.5727,  0.0450,  0.4311,\n",
            "            1.0875,  1.1647,  0.8172,  1.5314,  1.2226,  0.8172,  1.2998,\n",
            "            1.4156,  1.1647],\n",
            "          [ 0.7339,  0.5461,  0.4757,  1.1798,  0.7104,  1.0859,  1.8839,\n",
            "            0.8747, -0.8152, -1.5663, -1.5898, -1.1204, -0.2050,  0.6400,\n",
            "            1.0155,  1.3676,  1.3911,  0.6165, -1.0030, -1.8949, -0.8387,\n",
            "           -0.1815, -0.1111, -0.4397, -0.6979, -0.0172, -0.3223,  0.0767,\n",
            "           -0.5570, -1.2377],\n",
            "          [ 1.7038,  1.1431,  0.5357, -0.3987,  0.5357, -0.5388, -0.0716,\n",
            "            0.5357,  0.7693,  1.7972,  1.7038,  0.1152, -0.3987, -0.9593,\n",
            "           -1.5667, -0.9126, -1.7069, -1.5200,  0.4890,  0.4890,  0.0218,\n",
            "            0.1620,  0.7226,  1.0497,  0.7693, -0.5856, -0.8192, -1.3798,\n",
            "           -0.6323, -1.0528],\n",
            "          [ 1.3286,  1.3769,  1.3493,  1.0979,  0.2746,  1.0049,  1.4457,\n",
            "            1.4251,  1.3596,  1.1909,  1.2735, -0.2420,  0.3366, -0.2765,\n",
            "           -0.6657, -1.3029, -1.0274, -0.9240, -1.0170, -1.0377, -1.1548,\n",
            "           -0.6209, -0.4556, -0.7552, -0.9929, -1.0549, -0.5589, -0.5727,\n",
            "           -0.0491, -0.7552],\n",
            "          [-0.5188, -0.1604, -0.3206, -0.1182,  0.3287, -0.0760, -0.4134,\n",
            "           -1.1302, -1.8174, -1.9524, -1.5560, -0.9320, -1.1133, -0.5651,\n",
            "            0.2908,  1.1973,  1.1763,  1.1383,  0.9992,  0.6028,  1.0202,\n",
            "            1.0160,  0.9444,  1.3238,  0.6661,  0.8685,  0.9022,  0.3920,\n",
            "           -0.7675, -1.4253],\n",
            "          [-0.5079, -1.1047, -0.7546, -1.4088, -0.4275, -0.4792, -1.0703,\n",
            "           -1.0186, -0.8637, -0.6112, -1.0530, -0.1062,  0.2496,  0.4964,\n",
            "           -0.3529,  0.8292,  0.3300, -0.3300, -0.9383, -0.2496, -0.7202,\n",
            "            0.2668,  0.4849,  0.8809,  0.1865,  0.4964,  2.3844,  2.0975,\n",
            "            2.1262,  1.1678],\n",
            "          [ 0.8599,  0.4997,  0.1395,  0.7214,  0.9431,  1.1925,  1.1925,\n",
            "            1.7467,  1.8852,  1.3310,  0.7768,  0.3612,  0.1395, -0.4424,\n",
            "           -0.7195, -1.3015, -0.4147,  0.1395,  0.6937,  0.3057, -0.2208,\n",
            "           -0.9689, -0.9412, -1.2183, -1.2460, -1.2183, -0.4424, -1.4123,\n",
            "           -1.1075, -1.2738],\n",
            "          [ 1.2013,  0.8922,  1.0467,  1.3816,  1.1755,  1.5619,  1.5362,\n",
            "            0.5058, -0.9883, -1.3747, -1.6066, -0.5504,  0.1966,  0.4285,\n",
            "            0.7118,  0.9437,  1.1498, -0.0094, -1.4005, -1.6066, -0.9368,\n",
            "           -0.3186, -0.3701, -0.7050, -0.5247,  0.1709, -0.1382, -0.4731,\n",
            "           -0.7050, -1.1944],\n",
            "          [-0.6976, -0.6976, -0.0324, -0.4929,  0.6839,  1.4003,  0.5304,\n",
            "            1.3491,  0.2234, -1.0046, -0.4417, -0.5441,  0.0699,  1.2468,\n",
            "            1.8608,  1.3491,  2.3724,  1.0933,  0.3769, -0.8511, -0.6976,\n",
            "           -0.5441, -0.2371, -1.3116, -0.3394, -0.9022, -0.8511, -1.0046,\n",
            "           -1.2092, -0.6976],\n",
            "          [-0.9601, -1.2882, -0.8329, -0.6716, -1.2147, -1.0252, -0.8979,\n",
            "           -0.9884, -1.5598, -1.5796, -1.0111, -0.3945, -1.2769,  0.0835,\n",
            "            0.2221,  0.5417,  0.9745,  1.1951,  0.7454,  1.0112,  1.2205,\n",
            "            1.0084,  1.2347,  1.0593,  0.9575,  0.4229,  0.8727,  1.1612,\n",
            "            0.6860,  0.3041],\n",
            "          [ 0.4777,  0.0754,  1.0196, -0.3883, -0.2095, -0.1760,  0.6006,\n",
            "            1.3101,  0.8967,  0.7794, -0.2151, -2.0476, -2.5951, -2.2823,\n",
            "           -1.4107, -0.4106, -0.5671,  1.2319,  1.4554,  0.7123,  0.3548,\n",
            "            0.4051,  0.5447,  0.0866,  0.2877,  0.1089,  0.0866,  0.2263,\n",
            "            0.2654, -0.6229],\n",
            "          [ 1.3308,  1.5643,  0.9330,  1.2201,  1.0057,  0.8725,  0.6321,\n",
            "            0.2862,  0.4350,  0.4989,  0.8569,  1.2824,  1.4640,  0.9642,\n",
            "            0.0994, -0.5439, -0.4626, -1.3464, -1.5539, -0.5923, -0.1306,\n",
            "           -0.4920, -0.8829, -1.0437, -0.9693, -0.7860, -0.9244, -1.0904,\n",
            "           -1.2841, -1.3429]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL3-22.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[-2.2749e+00, -6.3749e-01, -1.0632e+00,  1.8121e-01,  8.3616e-01,\n",
            "            1.3274e+00,  4.4319e-01,  1.1571e-01,  4.7594e-01,  8.0342e-01,\n",
            "            8.3616e-01,  1.1309e+00,  1.0654e+00,  1.1571e-01, -1.7902e-01,\n",
            "            1.7466e-02,  7.0517e-01,  8.6891e-01,  1.0654e+00,  9.0166e-01,\n",
            "            8.6891e-01, -1.1353e-01,  1.8121e-01, -4.7375e-01, -1.1353e-01,\n",
            "           -6.3749e-01, -1.2270e+00, -1.3907e+00, -1.6527e+00, -2.1766e+00],\n",
            "          [ 3.1086e-01, -1.8233e-01, -2.9891e-03, -1.8233e-01,  8.6683e-02,\n",
            "           -7.6520e-01, -2.2717e-01,  1.2076e+00,  8.4890e-01,  1.1628e+00,\n",
            "            1.6559e+00,  8.0406e-01,  8.4890e-01,  1.1628e+00,  7.5923e-01,\n",
            "            7.5923e-01,  9.3857e-01,  1.0731e+00, -1.3750e-01,  4.1847e-02,\n",
            "           -1.3032e+00, -9.2661e-02, -4.9619e-01, -2.9891e-03, -8.5488e-01,\n",
            "           -1.5723e+00, -4.5135e-01, -1.2136e+00, -1.6171e+00, -2.5586e+00],\n",
            "          [-1.3209e+00, -1.4502e+00, -4.1587e-01, -2.2194e-01,  5.2146e-01,\n",
            "           -1.3532e+00, -6.0334e-02, -2.5426e-01,  6.8306e-01,  7.1539e-01,\n",
            "            9.0932e-01,  9.4164e-01,  1.9759e+00,  1.3618e+00,  1.2002e+00,\n",
            "            1.6850e+00,  4.2449e-01,  1.2972e+00,  6.8953e-02,  3.9217e-01,\n",
            "           -3.5123e-01, -3.8355e-01, -7.0677e-01, -3.1891e-01, -1.2498e-01,\n",
            "           -3.8355e-01, -1.0300e+00, -1.0300e+00, -6.7444e-01, -2.0966e+00],\n",
            "          [ 8.6588e-01,  8.6588e-01,  9.2579e-01,  1.0696e+00,  1.0696e+00,\n",
            "            9.8570e-01,  9.4975e-01,  7.8201e-01,  7.8201e-01,  5.9030e-01,\n",
            "            3.1472e-01,  4.2256e-01,  5.4237e-01,  5.5435e-01,  5.3039e-01,\n",
            "            7.5804e-01,  7.1012e-01, -4.4732e-02, -1.0991e+00, -1.0632e+00,\n",
            "           -1.5784e+00, -1.9139e+00, -1.7941e+00, -1.7941e+00, -1.4945e+00,\n",
            "           -7.8760e-01, -6.4382e-01, -5.8391e-01, -2.1248e-01,  2.9076e-01],\n",
            "          [-1.2874e-01, -8.0042e-01, -3.5263e-01,  9.5154e-02,  8.2281e-01,\n",
            "            9.9073e-01,  1.8863e+00,  1.5225e+00,  7.6683e-01,  2.6307e-01,\n",
            "           -2.9666e-01, -8.8438e-01, -3.2464e-01, -7.2765e-02, -1.2874e-01,\n",
            "           -1.2482e+00, -1.8359e+00, -9.1236e-01,  2.4180e+00,  1.2706e+00,\n",
            "            4.5898e-01,  2.0710e-01, -6.0451e-01, -5.7652e-01, -1.0075e-01,\n",
            "           -7.7243e-01, -1.5561e+00, -1.1083e+00,  2.9106e-01,  7.1086e-01],\n",
            "          [ 4.2606e-01,  1.1583e+00,  1.3913e+00,  1.7242e+00,  1.3913e+00,\n",
            "            1.0585e+00, -7.3228e-02,  5.5920e-01, -6.3908e-01, -1.4712e+00,\n",
            "           -1.3714e+00, -1.1051e+00, -7.3228e-02, -7.3894e-01,  9.3200e-02,\n",
            "            1.9306e-01,  6.2577e-01,  1.3248e+00,  2.2634e-01,  1.0918e+00,\n",
            "            1.0918e+00, -6.6571e-03, -4.0609e-01, -4.3937e-01, -7.0566e-01,\n",
            "           -3.7280e-01, -4.3937e-01, -1.0385e+00, -1.8707e+00, -1.6044e+00],\n",
            "          [ 5.3974e-01,  3.7584e-01,  1.2999e-01,  1.1553e-01,  1.8784e-01,\n",
            "           -4.9812e-03,  1.8302e-01,  1.7338e-01, -1.6068e-04,  3.3583e-02,\n",
            "           -2.2190e-01,  3.9994e-01,  5.3010e-01,  6.2651e-01,  7.6967e-02,\n",
            "            1.2035e-01,  1.1037e+00, -7.8108e-01, -4.2437e-01, -3.0178e+00,\n",
            "            7.5666e-01,  1.5665e+00,  5.5420e-01,  6.6989e-01, -2.4490e+00,\n",
            "           -1.9043e+00,  1.4445e-01,  1.4749e+00, -5.8007e-02, -9.0160e-01],\n",
            "          [-5.2592e-01, -1.0147e+00, -7.6705e-01, -2.3917e-01, -4.2165e-01,\n",
            "           -1.3490e-01, -1.8704e-01, -5.0181e-02, -2.1962e-01, -5.1940e-01,\n",
            "            1.6488e-01, -1.3490e-01, -3.8906e-01, -1.2232e+00,  7.3642e-02,\n",
            "            1.4989e-02, -2.2725e+00, -6.6930e-01, -1.0232e-01,  3.4736e-01,\n",
            "           -4.9985e-01, -5.0181e-02,  9.3389e-01,  1.9375e+00,  2.8890e+00,\n",
            "            2.1135e+00,  1.3230e-01, -5.9109e-01,  7.7096e-01,  6.3410e-01],\n",
            "          [-1.7623e-01,  2.6608e-01, -1.2094e-01,  1.3477e-01,  2.1770e-01,\n",
            "           -1.8314e-01, -2.5917e-01,  6.8074e-01, -1.2094e-01,  5.6325e-01,\n",
            "            1.9697e-01, -1.2785e-01, -4.2503e-01,  7.8441e-01,  1.3477e-01,\n",
            "            4.0430e-01,  1.4548e+00,  8.4661e-01,  7.7750e-01,  2.6228e+00,\n",
            "            5.9781e-01, -3.1445e-01, -8.7425e-01, -3.3484e+00, -8.8807e-01,\n",
            "           -1.0712e-01,  2.1079e-01, -5.5634e-01, -1.4479e+00, -9.4336e-01],\n",
            "          [-1.5387e-02,  8.7195e-02,  9.5915e-01,  1.1387e+00,  9.0785e-01,\n",
            "            1.0104e+00,  1.0874e+00,  1.8824e+00,  1.7542e+00,  1.2412e+00,\n",
            "            7.0269e-01,  6.7704e-01,  4.4623e-01,  3.6930e-01, -4.1033e-02,\n",
            "            2.6671e-01, -2.9749e-01, -5.2830e-01, -7.3346e-01, -9.8992e-01,\n",
            "           -1.5028e+00, -1.2977e+00, -1.3233e+00, -1.4515e+00, -1.0669e+00,\n",
            "           -1.2720e+00, -1.0156e+00, -8.6169e-01, -4.1033e-02, -9.2324e-02],\n",
            "          [ 4.9301e-01,  8.2746e-01,  1.1991e+00,  6.4165e-01,  8.4232e-02,\n",
            "            9.9097e-03,  4.7071e-02, -2.5022e-01, -5.8467e-01, -9.9345e-01,\n",
            "           -5.8467e-01,  4.5585e-01,  3.8152e-01,  9.0178e-01,  8.2746e-01,\n",
            "            5.6733e-01,  1.6822e+00,  1.0876e+00, -1.4394e+00, -2.1083e+00,\n",
            "           -1.3651e+00, -9.9345e-01,  4.7071e-02,  8.4232e-02,  8.6462e-01,\n",
            "            1.0876e+00,  8.6462e-01, -4.7319e-01, -1.2536e+00, -2.1083e+00],\n",
            "          [-3.4580e-01,  3.1765e-01, -2.2517e-01, -5.2674e-01,  7.6398e-02,\n",
            "           -3.4580e-01,  1.3430e+00, -1.0454e-01, -5.2674e-01,  7.3985e-01,\n",
            "           -4.0612e-01,  1.9703e-01,  3.1765e-01,  1.3430e+00,  4.9860e-01,\n",
            "            7.6398e-02,  5.5891e-01,  1.6446e+00,  4.9860e-01, -1.4315e+00,\n",
            "           -1.6727e+00, -1.6124e+00, -2.1552e+00, -1.0093e+00, -8.2831e-01,\n",
            "            9.8111e-01,  4.9860e-01,  2.1271e+00,  4.9860e-01, -5.2674e-01],\n",
            "          [-6.4695e-02, -4.5752e-01, -3.8477e-01, -9.5801e-01,  8.9525e-02,\n",
            "           -1.5490e-01, -1.1707e-01, -2.1892e-01,  4.8788e-02,  2.2600e-02,\n",
            "            3.1067e-01, -2.1310e-01, -1.5228e-02, -3.2076e-01, -3.1785e-01,\n",
            "           -6.6412e-01,  2.3184e+00, -1.8109e-01, -8.2707e-01, -6.9322e-01,\n",
            "            9.9157e-01, -1.6593e+00, -1.4265e+00, -3.9641e-01,  2.0246e+00,\n",
            "            7.4976e-02,  2.5949e+00, -1.2723e+00,  1.1953e+00,  6.7149e-01],\n",
            "          [-5.2897e-01, -2.0398e-01, -4.4574e-01, -1.3177e+00, -2.9514e-01,\n",
            "           -1.6038e-01, -3.3873e-01, -2.7532e-01, -1.0886e-01, -7.7153e-02,\n",
            "           -4.5446e-02, -5.6860e-01, -3.0703e-01, -3.7440e-01, -3.5062e-01,\n",
            "           -5.8446e-01,  3.6674e-01, -4.2989e-01,  1.1309e-01,  9.9691e-01,\n",
            "           -1.5674e+00, -1.0561e+00,  9.6916e-01, -4.4574e-01,  4.0011e+00,\n",
            "            1.2426e+00,  1.0762e+00,  6.7588e-01, -2.9117e-01,  3.3107e-01],\n",
            "          [ 6.9660e-02, -6.9459e-02,  1.7249e-01,  1.2219e+00, -4.6867e-01,\n",
            "           -4.8288e-02,  1.1503e-01,  1.4829e-01, -2.8116e-01, -1.9346e-01,\n",
            "           -4.8682e-01, -2.4185e-01, -6.3410e-02,  6.9660e-02,  1.8761e-01,\n",
            "           -1.6321e-01,  1.3580e+00, -1.6179e+00, -4.9891e-01, -9.8281e-01,\n",
            "            4.8702e-01,  1.5667e+00,  3.2068e-01,  1.8903e+00, -2.2379e+00,\n",
            "            1.8843e+00, -2.3921e+00, -4.1121e-01,  4.0839e-01,  2.5717e-01]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-9.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0895,\n",
            "            0.2136,  0.8760],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.1080,\n",
            "            0.2726,  0.8354],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.9249,\n",
            "            0.1362, -1.0611],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0653,\n",
            "           -0.9184, -0.1469],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.1547,\n",
            "            0.5774,  0.5774],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
            "            0.0000, -1.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0515,\n",
            "            0.1126,  0.9390],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0676,\n",
            "           -0.1528, -0.9148],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0975,\n",
            "           -0.2378, -0.8596],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0911,\n",
            "           -0.2182, -0.8729],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0185,\n",
            "           -0.0381, -0.9804],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6958,\n",
            "            0.4502, -1.1460],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0273,\n",
            "           -0.0571, -0.9702],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1248,\n",
            "           -0.3361, -0.7886],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.8580,\n",
            "           -0.2402,  1.0982]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL4-84.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 1.4231,  1.1011,  1.6991,  2.3432,  0.8710,  1.1471,  0.3650,\n",
            "            0.7330,  0.7330,  0.6870,  0.2730,  0.1810, -0.0951, -0.5551,\n",
            "           -0.6931,  0.4110, -0.4631,  0.1349, -0.8312,  0.3190, -1.1532,\n",
            "           -1.1992, -1.4752, -1.1532, -1.1072, -0.1871, -0.6011, -0.2331,\n",
            "           -1.3832, -1.2912],\n",
            "          [ 1.0031,  0.8359,  0.6687,  0.4458,  1.6161,  1.2260,  1.7833,\n",
            "            0.6687,  1.2260,  0.1672,  0.6130,  0.1115, -0.0557, -0.2229,\n",
            "            0.6687, -0.2229, -0.5016,  0.1672,  0.5016, -0.1115,  0.7245,\n",
            "           -1.1146, -1.5604, -0.9474, -0.9474, -1.0588, -2.0062, -1.3375,\n",
            "           -0.8359, -1.5047],\n",
            "          [ 0.0000,  0.5049,  1.5148, -0.0631,  0.8836,  0.1893, -0.7574,\n",
            "           -1.3254, -1.2623,  1.7672, -0.6943, -0.8836, -0.8205, -1.4516,\n",
            "            0.5049, -1.0730,  1.1361,  1.6410, -0.1893, -0.9467, -0.6312,\n",
            "            0.0631,  1.8303, -0.0631,  0.5049, -0.6312,  0.9467, -0.5680,\n",
            "            1.0730, -1.1992],\n",
            "          [ 1.2338,  0.9810,  0.8799,  0.8799,  0.0708,  0.1719,  0.5259,\n",
            "            0.3742,  0.4753,  0.4248,  0.0202,  1.5372,  2.1441,  1.6889,\n",
            "            0.5259, -0.7888, -0.2832, -0.9406, -0.6877, -0.9406, -0.4854,\n",
            "           -0.4854, -0.8394, -0.9911, -1.4968, -1.0923, -2.2553, -0.5360,\n",
            "            0.1719, -0.2832],\n",
            "          [-0.4882, -0.4882, -0.4882, -0.4882, -0.4472, -0.6933, -0.9395,\n",
            "           -1.0625, -1.6369, -1.3907, -0.6523,  0.2503,  0.3323, -0.0779,\n",
            "           -1.1856,  0.0451,  0.8246,  1.5630,  1.4400,  2.1784,  1.8092,\n",
            "            0.5374,  0.2503,  0.7015,  1.3989, -0.7754, -0.8164,  1.0707,\n",
            "           -0.3651, -0.4061],\n",
            "          [-1.0621, -1.0106, -0.0825, -1.5261,  0.4847,  0.2784, -1.1137,\n",
            "           -0.9590,  0.5362,  0.6909,  0.6909,  0.6909,  1.1549,  2.2377,\n",
            "            2.1345,  0.5878,  0.8456,  0.3300, -0.2372,  0.1753,  0.2784,\n",
            "           -0.4950, -0.3403, -0.4434, -2.4026,  0.2784, -0.0825, -0.9074,\n",
            "           -0.9074,  0.1753],\n",
            "          [-1.6327, -1.4048, -1.6016, -1.6948, -1.3116, -1.4670, -1.0838,\n",
            "           -0.7111, -0.4108, -0.0173, -0.1933,  0.2313,  0.0863, -0.0690,\n",
            "            0.3245,  0.5523,  0.5316,  0.0863,  0.1174,  0.2106,  0.4177,\n",
            "            0.6040,  0.6765,  0.5937,  0.8112,  0.8940,  1.1011,  0.3038,\n",
            "            1.9813,  2.0745],\n",
            "          [-0.8789, -0.9317, -0.9141, -0.9405, -1.0154, -0.8305, -0.8745,\n",
            "           -0.8569, -0.7953, -0.5839, -0.7204, -0.7600, -0.6676, -0.6368,\n",
            "           -0.5971, -0.3858, -0.2757,  0.0104,  0.1073,  0.2570,  0.4111,\n",
            "            0.5740,  0.6708,  0.8821,  1.0142,  1.1991,  1.4192,  1.7627,\n",
            "            2.0532,  2.3042],\n",
            "          [ 0.9398,  1.1514,  0.8340,  1.3479,  0.8491,  1.0002,  0.5014,\n",
            "            1.1817,  1.6503,  1.1363,  1.1514,  0.4409,  0.1839, -0.1638,\n",
            "            0.4409, -0.1638, -0.0277, -0.7382, -0.6777, -1.0406, -0.9347,\n",
            "            0.0176, -0.1940, -1.2220, -0.8743, -1.3127, -2.0081, -1.1161,\n",
            "           -1.3580, -0.9952],\n",
            "          [-2.2070,  0.1486, -1.3657, -1.4498, -1.8705,  0.3169, -0.4403,\n",
            "            0.1486, -0.3561,  0.0645, -0.3561,  0.9058,  1.2423,  0.0645,\n",
            "           -1.3657, -0.6927,  0.2328,  0.2328,  0.2328,  0.2328,  0.2328,\n",
            "            0.2328,  0.4010,  1.3264,  0.4851, -0.6085,  1.8312,  2.1677,\n",
            "           -0.3561,  0.5693],\n",
            "          [-0.6863, -0.9822, -1.4050, -0.9822, -0.6440, -0.6863, -0.6863,\n",
            "           -1.3204, -0.4326, -0.3058, -1.1091, -0.2635, -0.3481,  0.0324,\n",
            "            0.1592, -0.1790, -0.2635,  0.4975,  1.7658,  2.0617,  1.8503,\n",
            "            2.3576,  0.8779, -0.0944,  0.6666,  0.1592, -0.6017, -0.4326,\n",
            "           -0.1367,  1.1316],\n",
            "          [-0.7301,  0.7980,  1.4206,  0.4585,  0.6283, -0.7301,  0.4585,\n",
            "           -0.5037, -0.2207, -1.1829,  0.2887,  0.1755, -1.9187, -1.0697,\n",
            "           -1.0697, -2.3149, -1.4659,  0.3453, -0.2207, -0.1641,  0.4585,\n",
            "            0.8546,  0.2321,  0.5151,  1.3640,  1.9300, -0.4471,  0.1755,\n",
            "            1.0810,  0.8546],\n",
            "          [-0.9536,  0.7987,  0.4667, -0.0867, -0.2712, -0.3080, -0.4741,\n",
            "           -0.8430, -1.0459, -1.1934, -1.3963, -0.6401, -0.0682, -1.1566,\n",
            "           -1.0090, -0.3449,  1.1676,  0.3744,  1.0016,  0.7987, -0.6032,\n",
            "            0.2453,  1.6288,  0.9094,  0.4298,  1.7394,  1.9423, -1.3963,\n",
            "           -1.0274,  1.3152],\n",
            "          [-1.1642, -1.1143, -1.0493, -0.9495, -1.0943, -0.9345, -0.8696,\n",
            "           -0.8147, -0.7797, -0.8247, -0.7847, -0.5151, -0.5550, -0.6449,\n",
            "           -0.2705, -0.2355, -0.0458,  0.0291,  0.1939,  0.2688,  0.1939,\n",
            "            0.6433,  0.9778,  0.8380,  1.1226,  1.3872,  1.3223,  1.8615,\n",
            "            1.8116,  1.9963],\n",
            "          [-1.4962, -1.6394, -1.7747, -1.4405, -0.8676, -1.1859, -0.8755,\n",
            "           -0.9551, -0.6527, -0.2549, -0.0321, -0.1992,  0.1748,  0.3578,\n",
            "            0.2305,  0.1111,  0.0634,  0.4215,  0.1987,  0.1987,  0.0554,\n",
            "            0.0156,  0.3419,  0.7716,  0.8591,  1.1455,  1.0819,  1.2410,\n",
            "            2.2675,  1.8378]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL4-16.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000, -0.4392,  0.1303, -0.2794,\n",
            "            0.9096,  1.1094,  0.3401,  0.6298,  1.0495,  1.3892,  1.7489,\n",
            "            1.7289,  1.3392, -0.2694, -0.6091,  0.0603, -0.2894, -2.0379,\n",
            "           -0.5292,  0.1003, -0.1495, -1.3385, -1.3185, -0.9088, -0.6191,\n",
            "           -0.8189, -0.9288],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  2.0109,  1.0159, -0.5219,\n",
            "           -0.8449, -0.9612, -1.3618, -1.4135, -0.6511, -0.9354, -0.8708,\n",
            "           -0.2763, -0.3668, -0.3539,  1.5070,  2.4245,  0.3827,  1.3002,\n",
            "            0.8221, -0.8579, -0.1730, -0.3797,  0.2922,  0.1243,  0.0984,\n",
            "            0.2018, -0.2117],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.2774,  0.9891,  0.8149,\n",
            "            0.6855,  0.5362,  0.6507,  0.6407,  0.8846,  0.7253,  0.8995,\n",
            "            1.2280,  0.5959,  1.0439,  0.9393, -0.1656,  0.7253, -0.7529,\n",
            "           -0.2502, -0.5090, -1.5791, -1.2207, -1.2506, -1.5741, -1.3800,\n",
            "           -1.4945, -1.4597],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -1.8510, -1.4949, -0.8971,\n",
            "           -0.0323,  0.0440, -0.2358,  0.7054,  0.5909,  0.9724,  2.1552,\n",
            "            2.0916,  1.3413,  0.2857,  0.0313,  0.2984,  1.1378,  0.3365,\n",
            "           -0.0196, -0.4901, -0.4901, -0.2612, -0.5410, -0.8462, -1.1006,\n",
            "           -0.7699, -0.9607],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -2.0354, -1.7850, -0.6522,\n",
            "            0.2660,  1.6015,  2.4243,  1.0172,  0.7668,  1.6254,  0.8861,\n",
            "           -0.2110, -0.1752,  0.0752,  0.5403,  0.5999,  0.0633, -0.1037,\n",
            "           -0.1990, -0.6641, -0.4495, -0.5449, -0.4733, -0.6045, -0.5329,\n",
            "           -0.5568, -0.8787],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  2.1567,  1.8533,  1.4436,\n",
            "            1.1250,  0.6851,  0.6471,  0.9657,  0.7306,  0.0251, -0.4225,\n",
            "           -0.0204, -0.6425, -1.0066, -1.1583, -1.0976, -1.3252, -1.3176,\n",
            "           -1.3479, -0.9231, -0.6956, -0.3694, -0.1494,  0.1389,  0.4499,\n",
            "            0.1161,  0.1389],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -2.0182, -1.5019, -1.3338,\n",
            "           -1.0336, -1.4899, -1.3098, -0.3011, -0.4572, -0.4152, -0.1270,\n",
            "           -0.1030,  0.2092,  0.1132,  0.1672, -0.0189, -0.1510,  0.0891,\n",
            "            0.8877,  0.8997,  1.6622,  1.1518,  0.6355,  1.0978,  1.3259,\n",
            "            1.3079,  0.7135],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0361, -0.4272, -0.0081,\n",
            "           -0.8463, -1.2433, -1.4860, -1.9051, -1.5962, -0.8132, -1.0227,\n",
            "           -0.8022,  0.9846,  1.2051,  1.1941,  0.7640,  0.9956,  1.4368,\n",
            "            1.5360,  1.0507,  0.5985, -0.0191, -0.2507, -0.1073, -0.1735,\n",
            "            0.4331,  0.4662],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  1.6663,  1.3239,  1.2750,\n",
            "            1.4584,  1.2384,  0.8532,  0.6821,  0.2786,  0.2970,  0.2053,\n",
            "            0.4803, -0.3877,  0.4620,  0.2297, -0.0759, -0.0637,  0.1808,\n",
            "           -0.4305, -0.5833, -1.1152, -1.3352, -1.4025, -0.9318, -0.8645,\n",
            "           -1.8610, -1.5798],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  1.2180,  1.4286,  1.8359,\n",
            "            1.6814,  1.2039, -0.0178, -0.6076, -0.2285, -0.0319, -0.0178,\n",
            "           -1.2115, -2.0120, -1.4502, -0.6638, -0.3549, -0.3408, -0.6919,\n",
            "           -1.1413, -1.1694, -0.4532,  0.2771,  0.5720,  0.2911,  0.4035,\n",
            "            0.7686,  0.7124],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0285, -0.0692,  0.0324,\n",
            "            0.1950,  0.2051,  1.0685,  1.7999,  2.4398,  1.5053,  1.0279,\n",
            "            1.3428,  0.8755, -0.3637, -0.5466, -0.7599, -0.5669, -0.5364,\n",
            "           -0.7091, -1.1053, -1.2068, -1.0951, -1.0138, -0.8513, -0.6075,\n",
            "           -0.6481, -0.3840],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -1.7816, -1.7186, -1.5984,\n",
            "           -1.5984, -1.3809, -1.0031, -0.7226, -0.5509, -0.6825, -0.1673,\n",
            "            0.2391,  0.4566,  0.3421,  0.5883,  0.6856,  0.8688,  0.7715,\n",
            "            1.1894,  1.2752,  1.2695,  1.0062,  0.6513,  0.4166,  0.6055,\n",
            "            0.4166,  0.4223],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -0.5345, -0.7748,  0.7130,\n",
            "           -0.0263, -0.6269,  0.5559,  0.4727, -0.7748, -0.9411, -0.3035,\n",
            "           -0.6916,  0.0753,  0.3618, -0.3405, -0.9688, -0.5530, -0.5253,\n",
            "            0.3341,  0.7314, -0.1926, -0.5253,  0.2509,  2.4317,  2.8937,\n",
            "           -1.7451,  0.7037],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0183, -0.7424, -1.5349,\n",
            "           -1.5349, -1.1756, -0.5945, -0.3198, -1.0911,  0.0394,  1.5503,\n",
            "            1.4447,  0.9798,  1.7194,  0.6734,  0.7896,  0.4304,  0.1134,\n",
            "            1.7828, -0.2670, -0.7741, -1.2813, -0.1508,  0.1239, -0.6896,\n",
            "           -0.4255,  0.9164],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000, -1.8611, -1.4942, -1.4902,\n",
            "           -1.1470, -0.7880, -0.7840, -0.6420, -0.4290, -0.5710, -0.2948,\n",
            "           -0.3224, -0.4881, -0.7564, -0.2080,  0.2693,  0.8769,  1.1018,\n",
            "            0.1904,  0.4903,  0.8651,  1.4332,  1.3700,  0.9992,  1.0623,\n",
            "            1.2872,  1.3306]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-102.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.1145, -0.8015,  1.4885,  0.2290,  0.2290, -1.0305,  0.1145,\n",
            "            0.1145,  2.2900,  1.1450,  1.1450,  0.2290,  1.4885, -0.8015,\n",
            "           -0.2290, -0.5725,  0.1145,  1.1450, -1.2595,  0.1145, -0.9160,\n",
            "           -0.9160, -2.1755,  0.1145,  0.1145, -0.1145, -0.6870,  1.1450,\n",
            "           -1.6030, -0.2290],\n",
            "          [ 0.6601,  1.4852, -0.7544,  0.4243,  0.5422,  0.6601, -0.5186,\n",
            "            0.6601, -1.9331, -2.2868,  0.7780,  0.6601,  0.0707, -0.2829,\n",
            "            0.6601,  0.7780, -0.9901,  0.0707,  2.4282, -0.1650, -0.6365,\n",
            "           -0.5186, -0.6365,  0.6601, -1.6974, -0.2829,  0.4243,  0.8958,\n",
            "           -0.5186, -0.6365],\n",
            "          [-0.4024, -0.9772, -1.2235, -0.7308, -0.0739,  0.0903,  0.9115,\n",
            "           -0.8130, -0.7308, -1.0593, -1.1414,  0.8294, -1.3056, -0.2381,\n",
            "            0.0082,  0.2546, -0.0739,  0.4188, -1.3056, -0.4845,  0.3367,\n",
            "           -0.0739,  0.9115,  0.0903,  1.7327, -0.1560, -0.4845,  1.2400,\n",
            "            2.9644,  1.4863],\n",
            "          [ 2.6571,  2.6527,  1.7791,  1.5755,  1.3412,  0.1917,  0.0625,\n",
            "            0.7193,  0.4697, -0.1214, -0.2857, -0.3207, -0.5659, -0.7017,\n",
            "           -0.6645, -0.7039, -0.6842, -0.6688, -0.5572, -0.5769, -0.4477,\n",
            "           -0.6075, -0.5572, -0.5462, -0.4586, -0.6229, -0.6031, -0.6053,\n",
            "           -0.5331, -0.6163],\n",
            "          [ 0.1560, -0.4968, -1.0543, -1.1591, -1.3640, -1.8547, -1.3735,\n",
            "           -0.6874, -0.7017, -1.4688, -0.8494,  0.9326,  0.7611,  1.2375,\n",
            "            1.2804,  1.6521,  1.4805,  1.3757,  1.3090,  1.0851,  0.3847,\n",
            "           -0.2443, -0.5921, -0.3253,  0.0416, -0.0918,  0.0511,  0.0464,\n",
            "           -0.0203,  0.4895],\n",
            "          [ 1.5041,  1.2081,  1.1812,  0.9210,  1.0735,  1.8271,  1.4413,\n",
            "            0.4635,  0.7326,  1.3740,  1.4458, -0.4246, -0.3394, -0.2228,\n",
            "           -0.7162, -1.0750, -1.0302, -0.9404, -1.2948, -1.4563, -1.2858,\n",
            "           -0.7924, -0.4112, -0.5547, -0.5682, -0.5502, -0.5009, -0.2721,\n",
            "           -0.3573, -0.3798],\n",
            "          [-1.7382, -1.3203, -1.7243, -1.0556, -0.7073, -1.2785, -0.9998,\n",
            "           -0.8327, -0.7630, -0.4426, -0.4286, -0.0107, -0.4704, -0.0107,\n",
            "            0.2540, -0.0943,  0.3097,  0.1704, -0.2057,  0.2819,  0.7695,\n",
            "            0.6441,  0.4351,  0.5466,  1.2014,  1.2292,  1.0481,  1.5497,\n",
            "            1.4800,  2.1627],\n",
            "          [-0.8744, -1.2998, -0.9217, -1.8670, -1.6306, -1.1580, -0.8744,\n",
            "           -0.6853, -0.3072,  0.4490, -0.3072, -0.9217, -1.1580, -0.7799,\n",
            "            0.4017,  0.4490,  0.4490,  0.4490,  1.4888,  1.5834,  1.2525,\n",
            "            0.5908,  0.4490,  0.8271,  0.0709,  1.5361,  0.6381,  0.8744,\n",
            "           -0.1182,  1.3943],\n",
            "          [ 0.4069,  0.9577,  0.3152, -0.0979,  0.7741, -1.6584, -0.0061,\n",
            "            0.3152,  1.1413, -0.5110,  1.0954,  2.2428,  0.7741,  0.1775,\n",
            "           -0.1438,  0.1775,  1.9215, -1.3830, -0.7863,  0.5905,  0.7282,\n",
            "           -0.8322, -0.7863, -0.3274,  0.1775, -0.6946, -1.4748, -0.5110,\n",
            "           -2.0255, -0.5569],\n",
            "          [-2.7894, -2.5489, -1.8124, -1.5368, -1.0358, -0.0087,  0.2268,\n",
            "           -0.3344, -0.3043, -0.1891,  0.2168,  0.7178,  1.1387,  1.0385,\n",
            "            0.4773,  0.8982,  0.8731,  0.3420,  0.3020,  0.2919, -0.2993,\n",
            "           -0.0187,  0.3370,  0.2569,  0.6727,  0.5675,  0.6326,  0.5374,\n",
            "            0.5374,  0.8130],\n",
            "          [-0.2612, -0.6925, -1.4632, -1.6895, -1.7673, -1.8733, -1.5127,\n",
            "           -1.0885, -0.8975, -0.8480, -0.6501, -0.0207,  0.1348,  0.5308,\n",
            "            0.8631,  0.9338,  0.9480,  1.0611,  1.2167,  1.2167,  1.2733,\n",
            "            0.9551,  0.7571,  0.6934,  0.4389,  0.5449,  0.4742,  0.2833,\n",
            "            0.3257,  0.1136],\n",
            "          [-2.1357, -1.6189, -1.3154, -1.2633, -1.0783, -0.7370, -1.1874,\n",
            "           -1.2822, -1.0214, -0.2202, -0.4857, -0.5094, -0.1348,  0.0738,\n",
            "            0.4152,  0.4958,  0.6333,  0.6902,  0.9273,  1.1264,  1.3492,\n",
            "            1.3872,  1.3445,  0.8514,  0.7518,  0.8277,  0.6143,  0.5337,\n",
            "            0.6238,  0.3441],\n",
            "          [ 1.2660,  2.2228,  1.7321,  0.5054,  1.3641,  0.4318,  0.8244,\n",
            "            0.5054, -0.2061, -0.8195, -0.3533,  0.1129, -0.4514, -1.1139,\n",
            "            0.4318, -0.7949, -0.2306,  1.6585,  0.3091, -0.9421, -1.0893,\n",
            "            0.3337, -0.3042, -1.5800, -1.3837,  0.0638,  0.3827, -0.3533,\n",
            "           -1.0893, -1.4328],\n",
            "          [-1.5656, -1.4645, -1.2219, -1.2219, -1.4038, -1.0197, -1.0197,\n",
            "           -0.7568, -0.5951, -0.4333, -0.8781, -0.8984, -0.3727, -0.1503,\n",
            "            0.1125,  0.1125,  0.4360,  0.6989,  0.5371,  0.5169,  0.6787,\n",
            "            0.5573,  0.6382,  0.3754,  1.1437,  1.2043,  1.1235,  1.5076,\n",
            "            1.6896,  1.6694],\n",
            "          [-1.4173, -1.5957, -1.2984, -0.6444, -0.8823, -0.7990, -0.8347,\n",
            "           -0.7277, -0.9417, -0.4423, -0.7752, -0.3115,  0.0927, -0.1688,\n",
            "           -0.7039, -0.1570, -0.1094, -0.1807,  0.2949,  0.6991,  0.2116,\n",
            "            0.3305,  0.2592,  1.0202,  1.0796,  1.0083,  1.2223,  1.2699,\n",
            "            2.0784,  2.4232]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL4-28.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.9957, -1.0671,\n",
            "           -1.4460, -1.3417, -1.3471, -1.2703,  0.7230,  0.8658,  1.1458,\n",
            "            1.2886,  1.3105,  0.9262,  0.5253,  0.3331,  0.3441, -0.1721,\n",
            "           -0.2105,  0.3880],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.5830, -1.4826,\n",
            "           -1.3959, -1.3503, -1.1268, -0.9763,  0.8481,  0.8755,  1.0032,\n",
            "            0.8025,  0.7341,  0.6429,  0.7797,  0.8299,  0.8299,  0.4695,\n",
            "            0.0818,  0.0180],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.5194, -1.3219,\n",
            "           -1.3485, -1.3637, -1.2535, -1.1699,  0.4143,  0.5397,  0.5625,\n",
            "            0.4979,  0.4029,  0.5549,  0.8436,  0.7980,  0.2358,  0.7144,\n",
            "            1.1665,  1.2463],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.2920, -0.2547,\n",
            "           -0.0762, -0.9128, -0.3885,  0.1022,  2.0654,  2.2884,  1.1619,\n",
            "            0.0465,  0.0911,  0.4815,  0.2138, -0.4778, -1.0578, -1.2139,\n",
            "           -0.4220, -0.3551],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0644, -0.5700,\n",
            "           -0.8952, -0.8172,  0.1066,  0.2953,  0.6921,  0.4319,  1.0890,\n",
            "            2.1494,  1.7591,  0.7832,  0.1261, -0.2577, -0.8627, -1.1229,\n",
            "           -0.9928, -0.8497],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4017, -1.1937,\n",
            "           -1.1341, -0.6572, -1.4237, -1.7388, -0.1632,  0.2285, -0.1717,\n",
            "           -0.4869, -0.2739,  0.5947,  0.9524,  1.2164,  1.2761,  1.2931,\n",
            "            1.1228,  0.9609],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2531,  2.1898,\n",
            "           -1.0189, -0.1950, -0.6894, -0.9608,  0.5418,  0.6872,  1.2688,\n",
            "            1.1331,  0.7647,  0.9586,  0.1637, -0.8832, -0.5149, -1.2128,\n",
            "           -0.9802, -0.9996],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.2027,  1.4316,\n",
            "            1.7651,  1.4937,  0.9378,  0.7089, -0.0530, -0.0825,  0.0679,\n",
            "           -0.2525, -0.7234, -0.7757, -0.7136, -0.8673, -0.9229, -1.0308,\n",
            "           -1.0308, -1.1551],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.7264, -1.4723,\n",
            "           -1.4560, -1.4182, -1.6506, -1.2452,  0.4952,  0.7384,  0.4519,\n",
            "            0.1709,  0.6141,  0.5708,  0.7600,  0.8141,  0.5438,  0.8843,\n",
            "            0.9654,  0.9600],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.9963,  1.5721,\n",
            "            0.8361,  0.3252,  0.4724,  0.9226, -0.5147, -1.2594, -1.5538,\n",
            "           -1.1295, -0.8438, -1.1035, -0.8524, -0.0558,  0.2906,  0.4984,\n",
            "            0.3598,  0.0394],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.8592, -1.0927,\n",
            "           -0.9457, -0.7814, -0.5478, -0.6516, -0.5132,  0.7842,  0.5853,\n",
            "            0.0490,  0.7756,  1.7098,  2.0817,  1.1994,  0.4296, -0.2451,\n",
            "           -0.7468, -1.2311],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.5162, -0.0965,\n",
            "           -0.2682, -1.0887,  0.6477,  1.0293, -0.0965,  0.8194,  0.4378,\n",
            "            0.2088,  1.3918,  1.6781,  0.2852,  0.5332, -0.3827, -0.8025,\n",
            "           -1.9855, -1.7947],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.4815,  1.5778,\n",
            "            1.7934,  1.1101,  0.6148,  0.3121, -1.1325, -1.2517, -1.3113,\n",
            "           -1.2334, -0.6831, -0.4400, -0.2428,  0.0874,  0.0736, -0.4262,\n",
            "           -0.5730,  0.2433],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.4819,  1.3454,\n",
            "            1.2920,  1.0665,  0.9330,  1.3187,  0.5294, -0.1621, -0.2748,\n",
            "           -0.2066, -0.5330, -0.7200, -1.0108, -1.0553, -1.2749, -1.1473,\n",
            "           -0.8950, -0.6873],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7493,  0.7633,\n",
            "            0.7680,  1.3822,  1.7291,  1.9400, -0.1367,  0.1305, -0.3664,\n",
            "           -0.6102, -0.3852, -0.4930, -0.8165, -0.8634, -0.9618, -1.0415,\n",
            "           -1.4634, -0.3242]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-174.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8836,\n",
            "            0.2020, -1.0856],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0960,\n",
            "            0.8628,  0.2332],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0976,\n",
            "           -0.2382, -0.8594],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.1086,\n",
            "            0.2746,  0.8340],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.9673,\n",
            "            0.0624, -1.0297],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3919,\n",
            "            0.7447, -1.1366],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.7741,\n",
            "           -1.1291,  0.3550],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.8112,\n",
            "            1.1173, -0.3061],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.0732,\n",
            "            0.1677,  0.9056],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6123,\n",
            "            0.5417, -1.1540],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0852,\n",
            "           -0.2010, -0.8843],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0911,\n",
            "           -0.8729, -0.2182],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.1533,\n",
            "            0.6265,  0.5268],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0027,\n",
            "           -0.0055, -0.9972],\n",
            "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.9918,\n",
            "            0.0163, -1.0080]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-72.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 2.4852,  1.6929,  1.5244,  1.3052,  0.7996, -0.0433, -1.9817,\n",
            "           -2.0155, -1.9143, -0.6164, -1.0041, -0.8861, -0.3635,  0.1590,\n",
            "            0.2601,  0.1253,  0.5973,  0.3950,  0.3444, -0.0770, -0.2287,\n",
            "           -0.2118, -0.2118, -0.5321, -0.1781,  0.1590,  0.3107,  0.0410,\n",
            "            0.0579,  0.0073],\n",
            "          [ 2.8348,  1.5026,  1.6721,  1.2361,  1.2361,  0.9212, -0.2414,\n",
            "            1.8659,  0.0977, -0.7501, -1.1618, -0.5563, -0.4594, -0.6532,\n",
            "           -0.9681, -0.9681, -0.7016, -1.0407, -0.7501, -0.1930, -0.2414,\n",
            "           -0.4110, -0.4836,  0.2430, -0.0234, -0.1930, -0.2899, -0.4110,\n",
            "           -0.3141, -0.7985],\n",
            "          [ 1.9278,  1.5293,  0.7088,  2.0451,  0.4978,  2.7484, -0.5337,\n",
            "           -0.9323, -1.5887,  0.2165, -0.2055, -0.8385, -1.4246, -0.6744,\n",
            "           -0.7682, -0.3696, -0.3227, -0.2290,  0.1930, -0.5806, -0.6510,\n",
            "           -0.6978,  0.0055, -0.2055, -0.2290, -0.4165, -0.2524, -0.2993,\n",
            "            0.7322,  0.6150],\n",
            "          [-0.0126, -0.7083, -0.9806, -0.6478,  0.0479, -0.2243,  0.2748,\n",
            "           -0.0277, -0.0580, -1.0411, -0.4663, -0.9957, -1.1469, -1.7368,\n",
            "           -0.7991, -1.0713, -0.3605,  0.4260,  0.0630, -0.3756, -0.2546,\n",
            "           -0.5117,  0.2143,  1.7418,  0.5773,  1.7721,  1.1822,  0.8797,\n",
            "            1.9233,  2.3166],\n",
            "          [ 2.1399,  1.8074,  1.1424,  1.2136,  0.8574,  0.1211,  0.2161,\n",
            "            0.5011, -0.4251, -0.8051,  0.1449,  0.5011,  0.1449,  0.5486,\n",
            "           -0.2114, -1.4701, -0.6864, -0.0926, -0.0689,  1.1186,  1.5699,\n",
            "           -0.9714, -1.2089, -0.3776, -1.4939, -0.1401, -1.0426, -1.5176,\n",
            "           -0.4726, -1.0426],\n",
            "          [-1.5473, -1.4844, -1.4424, -1.8200, -1.5053, -0.6873, -0.9810,\n",
            "           -1.0858,  0.0049,  0.2986,  1.0537,  0.6551,  1.4312,  0.2986,\n",
            "            0.4034,  0.7390,  0.9488,  0.6132,  0.8859,  0.2776, -0.6873,\n",
            "            0.0678,  0.1098, -0.8551,  1.2844,  0.6971,  1.7459,  0.8020,\n",
            "           -0.5824,  0.3615],\n",
            "          [ 0.8062,  0.5212, -0.1176, -0.1766,  0.1969, -0.4714, -0.3436,\n",
            "           -0.8645, -0.9136,  0.5605, -0.8448, -1.4443, -1.4050, -0.1766,\n",
            "           -0.1078, -0.5697, -1.1102,  1.0322,  0.4819,  2.1722, -0.9038,\n",
            "            1.3762, -0.4223, -1.6900, -0.6581, -0.0979,  0.7767,  1.7398,\n",
            "            1.2091,  1.4450],\n",
            "          [ 0.4014,  0.2256, -0.0381, -0.3384, -0.6387, -1.0489, -0.9903,\n",
            "           -0.9829, -0.4776, -0.2285, -0.2285, -0.2944, -0.2212, -0.0894,\n",
            "           -0.1773,  0.0059,  0.0645, -0.8731, -0.8365, -1.4957, -1.1807,\n",
            "           -0.8072,  0.9214,  1.2364,  1.9908,  2.3936,  2.1226,  1.4268,\n",
            "            0.4893, -0.3311],\n",
            "          [ 0.4030, -0.8271, -0.2648,  0.2273, -0.9325, -0.0715,  0.8423,\n",
            "            0.7545,  0.3503, -0.3878,  0.1746,  1.6682,  1.5804, -0.5108,\n",
            "            0.4909,  0.2976, -0.5284, -0.2120,  1.2992, -0.6514,  0.3503,\n",
            "           -2.1626, -1.0204, -1.2313, -0.2472,  2.2657,  1.2289, -0.4581,\n",
            "           -1.3718, -1.0555],\n",
            "          [ 0.4991,  0.8633,  0.8633,  0.1135,  0.0493,  0.4134, -0.1435,\n",
            "           -0.2721, -0.0364,  0.6277,  0.6919,  0.3278,  1.5702,  1.2917,\n",
            "            0.9062,  0.8847,  0.3063, -0.2721,  0.1992,  0.0493,  0.0064,\n",
            "            1.2275, -0.1649, -2.7356, -0.6791, -1.7502, -1.3217, -0.1649,\n",
            "           -1.4288, -1.9216],\n",
            "          [ 1.8244,  1.9811,  1.3024,  0.1801,  0.2845,  0.5455,  0.4672,\n",
            "            0.4933,  0.0235, -0.4724,  0.2845,  0.5194,  0.7021,  0.3889,\n",
            "           -0.3680, -1.0466, -0.4463, -0.0548,  0.5716,  0.9892,  1.5634,\n",
            "           -0.0287, -1.8558, -1.5426, -0.7334, -1.2554, -1.2032, -0.9161,\n",
            "           -0.8378, -1.3599],\n",
            "          [-0.2142,  0.4765,  0.5065,  0.4765,  0.7167,  1.2272,  1.7678,\n",
            "            0.8669,  0.8068, -0.9950, -1.2352, -0.8448, -0.4545, -0.9349,\n",
            "           -0.0941,  0.3263, -0.7247, -0.2442, -0.1842, -0.6647,  0.4765,\n",
            "            1.2873, -0.2743,  1.7978,  1.4374, -1.6557, -1.8959,  0.4164,\n",
            "           -0.8749, -1.2953],\n",
            "          [ 0.1818,  1.2242,  0.0497, -0.1485,  1.9216,  1.2389,  0.6810,\n",
            "           -0.1265, -0.8533,  0.2699,  1.2976,  1.0040, -0.0604, -0.0678,\n",
            "           -0.1852,  0.3580,  0.0277, -1.6901, -2.2774, -1.6094,  0.8718,\n",
            "            1.5178,  0.4167,  0.2919, -0.8606, -1.2497, -0.8679, -0.9927,\n",
            "           -0.2513, -0.1118],\n",
            "          [ 0.3800, -0.5097,  0.4171, -1.1276, -1.4180, -1.6342, -1.0226,\n",
            "           -0.8743, -0.0896,  0.0093, -1.2512, -0.3676, -0.6271, -0.9175,\n",
            "            0.4232,  0.1019, -0.5777,  0.2749, -0.8557, -0.8557,  1.3438,\n",
            "            1.4860,  1.5539,  1.4303,  1.7269,  1.5972,  1.1708,  0.3614,\n",
            "            0.1823, -0.3306],\n",
            "          [-0.4866, -0.3834, -1.1488, -0.5812, -0.4780, -0.1469, -1.1703,\n",
            "           -0.5683, -1.6819, -2.2839, -0.6543, -1.1273, -0.2028,  0.2788,\n",
            "           -0.6027, -0.1684,  1.7278,  0.3519,  1.1903,  2.1707,  1.5171,\n",
            "            0.1025,  0.3046,  0.3261,  0.1885,  0.4035,  0.4336,  0.6314,\n",
            "            0.7947,  1.2634]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL1-53.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 2.0886e+00,  1.6218e+00,  1.5180e+00,  1.0253e+00,  6.8814e-01,\n",
            "            9.4748e-01,  1.1290e+00,  1.5959e+00,  9.7342e-01,  1.6944e-01,\n",
            "           -2.9739e-01,  7.4001e-01, -5.3080e-01, -4.5299e-01, -6.6047e-01,\n",
            "           -1.1532e+00, -4.2706e-01, -9.4575e-01, -4.7893e-01, -9.7169e-01,\n",
            "           -1.4126e+00, -4.7893e-01,  9.1636e-02,  4.0285e-01, -2.9739e-01,\n",
            "           -9.4575e-01, -9.9762e-01, -7.6421e-01, -9.9762e-01, -1.1792e+00],\n",
            "          [ 1.8094e+00,  1.6209e+00,  5.8429e-01, -3.5811e-01, -1.2251e-01,\n",
            "           -7.5392e-02,  9.6125e-01,  1.1969e+00,  8.6701e-01,  2.5445e-01,\n",
            "            3.9581e-01, -1.4890e+00, -1.2251e-01,  1.7152e+00,  1.4325e+00,\n",
            "            2.5445e-01,  7.2565e-01, -2.8272e-02, -1.1592e+00, -1.3476e+00,\n",
            "           -1.3476e+00, -1.3476e+00, -9.2356e-01,  1.1309e-01, -7.5392e-02,\n",
            "            2.0733e-01, -4.9947e-01, -1.0649e+00, -1.0649e+00, -1.1120e+00],\n",
            "          [ 1.8737e+00,  2.1463e+00,  1.2603e+00,  1.1751e+00,  1.2944e+00,\n",
            "            1.1581e+00,  1.0729e+00,  1.2262e+00,  7.1507e-01,  6.7588e-02,\n",
            "            6.8099e-01, -6.6509e-01,  1.5278e-01,  8.4627e-02, -1.7607e-02,\n",
            "           -8.1844e-01, -1.0059e+00, -6.9917e-01, -9.2067e-01, -6.3101e-01,\n",
            "           -8.5252e-01, -8.0140e-01, -7.5028e-01, -1.1933e+00, -1.2444e+00,\n",
            "           -8.6956e-01, -9.3771e-01, -3.9247e-01, -3.7543e-01, -7.3325e-01],\n",
            "          [-8.8236e-01, -4.5917e-01, -7.9772e-01, -9.4584e-01, -4.8033e-01,\n",
            "           -6.7076e-01,  1.3331e-01, -5.7131e-02,  7.6810e-01,  1.4029e+00,\n",
            "            1.7626e+00,  1.8896e+00,  1.5722e+00,  1.9107e+00,  1.4241e+00,\n",
            "            9.3738e-01,  4.5070e-01,  9.0987e-02, -6.0729e-01, -5.0149e-01,\n",
            "           -1.0305e+00, -1.4960e+00, -1.2632e+00, -6.4961e-01, -6.7076e-01,\n",
            "           -7.1308e-01, -4.8033e-01, -5.7131e-02, -3.3221e-01, -2.4757e-01],\n",
            "          [ 1.2421e+00,  1.1423e+00,  1.6165e+00,  1.3170e+00,  7.6792e-01,\n",
            "            2.6873e-01, -4.5509e-01, -1.0042e+00, -1.9776e+00, -1.6781e+00,\n",
            "           -1.5533e+00, -1.7779e+00, -1.3536e+00, -1.1789e+00, -3.0534e-01,\n",
            "           -2.8038e-01,  9.4013e-02,  4.4344e-01,  6.9304e-01,  5.6824e-01,\n",
            "            4.9336e-01,  7.4296e-01, -2.3046e-01, -1.8054e-01, -2.3046e-01,\n",
            "            1.4393e-01,  1.6889e-01,  5.1832e-01,  1.0175e+00,  9.6759e-01],\n",
            "          [ 1.8481e+00,  1.5358e+00,  1.6920e+00,  1.8169e+00,  1.5045e+00,\n",
            "            1.4733e+00,  1.4108e+00,  1.6139e-01,  9.8915e-02, -9.0064e-01,\n",
            "           -5.5705e-01, -1.0568e+00, -1.2755e+00, -1.0881e+00, -8.6941e-01,\n",
            "           -7.4446e-01, -4.9457e-01, -4.9457e-01,  9.8915e-02, -5.7266e-02,\n",
            "           -1.1974e-01, -4.3210e-01,  1.9262e-01, -1.8221e-01, -9.0064e-01,\n",
            "           -1.3067e+00, -5.8828e-01, -7.7570e-01, -2.6030e-02,  3.6442e-02],\n",
            "          [ 8.3851e-01,  2.7322e-01,  9.5157e-01,  6.6085e-01,  1.5209e-01,\n",
            "            1.1696e+00,  1.4926e+00,  1.0566e+00,  6.8508e-01,  9.6772e-01,\n",
            "            3.0553e-01,  1.7995e+00,  5.4779e-01,  2.4092e-01, -1.3055e-01,\n",
            "            2.1669e-01, -3.8090e-01, -7.4026e-02,  1.8439e-01, -3.9705e-01,\n",
            "           -2.7955e+00, -4.9395e-01, -6.5547e-01, -3.8090e-01, -2.8399e-01,\n",
            "           -1.0996e+00, -6.3124e-01, -1.8749e+00, -1.0027e+00, -1.3419e+00],\n",
            "          [-2.5657e+00, -2.4414e+00, -1.9539e+00, -1.6479e+00, -1.3133e+00,\n",
            "           -9.8346e-01, -6.6796e-01,  2.3073e-01,  4.5540e-01,  3.6935e-01,\n",
            "            3.3589e-01,  7.8046e-01,  5.4144e-01,  8.0914e-01,  7.4700e-01,\n",
            "            4.9842e-01,  5.5100e-01,  3.8848e-01,  3.4737e-02,  2.2117e-01,\n",
            "            5.8447e-01,  4.4584e-01,  6.8485e-01,  6.7051e-01,  3.2155e-01,\n",
            "            8.0914e-01,  6.6095e-01,  6.2271e-01,  5.4144e-01,  2.6897e-01],\n",
            "          [-3.5639e-02, -3.3980e-01,  2.8696e-01,  4.4365e-01, -1.5546e-01,\n",
            "           -8.0066e-01, -3.5639e-02, -1.4182e+00,  1.4575e+00, -6.3291e-02,\n",
            "            6.5748e-02, -1.1325e+00, -4.4856e-02,  1.2087e+00,  8.8607e-01,\n",
            "            5.6347e-01, -4.5041e-01, -1.0034e+00,  1.3561e+00,  1.4114e+00,\n",
            "            8.4183e-02, -1.9344e+00,  1.7986e+00, -3.7667e-01,  1.2087e+00,\n",
            "           -7.5457e-01,  3.6991e-01, -1.1325e+00,  5.4504e-01, -2.0081e+00],\n",
            "          [-8.2474e-01,  9.7100e-02,  5.0271e-01, -4.9288e-01, -3.0851e-01,\n",
            "           -1.0829e+00, -3.8226e-01, -1.9789e-01, -1.3410e+00, -1.3410e+00,\n",
            "           -1.7466e+00, -1.4516e+00, -1.4147e+00, -6.7724e-01, -6.7724e-01,\n",
            "           -1.9789e-01,  5.0271e-01,  8.3457e-01,  1.2033e+00,  9.8206e-01,\n",
            "            1.6089e+00,  2.1989e+00,  1.3508e+00,  8.7144e-01,  6.8708e-01,\n",
            "            7.9770e-01,  1.3397e-01, -1.3520e-02,  3.9209e-01, -1.3520e-02],\n",
            "          [ 1.2910e+00,  1.5773e+00,  1.3115e+00,  1.1479e+00,  8.4113e-01,\n",
            "           -3.8171e-02, -3.6535e-01, -1.1424e+00, -1.6536e+00, -1.8172e+00,\n",
            "           -1.6741e+00, -1.8172e+00, -1.4900e+00, -8.7658e-01, -6.7209e-01,\n",
            "           -2.4266e-01,  1.2542e-01,  5.9575e-01,  7.3889e-01,  3.9126e-01,\n",
            "            4.5260e-01,  3.7081e-01,  2.7265e-03, -1.4042e-01, -1.6087e-01,\n",
            "            1.8677e-01,  4.1171e-01,  8.0024e-01,  8.4113e-01,  1.0047e+00],\n",
            "          [-1.9819e+00, -2.2089e+00, -1.8197e+00, -1.4305e+00, -1.3007e+00,\n",
            "           -9.7635e-01, -5.2223e-01, -7.1685e-01, -3.9249e-01, -1.3299e-01,\n",
            "            2.8869e-01,  8.4011e-01,  1.5894e-01,  1.5894e-01,  2.5625e-01,\n",
            "            1.1320e+00,  7.4280e-01,  2.5625e-01,  2.9193e-02,  9.6986e-01,\n",
            "            7.1037e-01,  8.0768e-01,  1.0996e+00,  1.6510e+00,  8.4011e-01,\n",
            "            1.0996e+00,  6.1306e-01,  1.9138e-01, -1.6543e-01, -1.9786e-01],\n",
            "          [-3.0969e-01,  6.6037e-02,  1.3526e+00, -1.0384e+00, -1.7306e-01,\n",
            "            3.0514e-01, -3.5523e-01,  1.4779e+00,  2.3682e-01, -6.5126e-01,\n",
            "           -1.5029e-01, -3.4385e-01, -6.3988e-01,  2.0494e-02, -9.4729e-01,\n",
            "           -1.2092e+00, -6.5126e-01, -7.5373e-01, -1.1864e+00,  7.7423e-02,\n",
            "            3.0514e-01,  1.5712e-01,  1.3435e-01,  1.9333e+00, -1.6646e+00,\n",
            "           -1.2661e+00,  6.8086e-01,  1.1363e+00,  2.6734e+00,  7.8334e-01],\n",
            "          [-2.0672e+00, -2.1551e+00, -1.7243e+00, -1.4649e+00, -1.6979e+00,\n",
            "           -1.2978e+00, -9.7242e-01, -6.9542e-01, -3.2170e-01, -1.8100e-01,\n",
            "            2.3669e-01,  3.8618e-01,  3.7739e-01,  7.2034e-01,  7.4672e-01,\n",
            "            5.7524e-01,  6.3680e-01,  7.5991e-01,  6.9835e-01,  5.6645e-01,\n",
            "            6.0162e-01,  4.9610e-01,  5.9723e-01,  4.3894e-01,  1.3359e+00,\n",
            "            7.2473e-01,  6.2361e-01,  6.3240e-01,  6.2361e-01,  7.9948e-01],\n",
            "          [-1.7191e+00, -1.5535e+00, -2.0943e+00, -6.0442e-01,  5.7757e-02,\n",
            "           -6.2649e-01,  4.8817e-01,  6.5372e-01,  8.6341e-01,  1.0841e+00,\n",
            "            8.3030e-01,  1.4483e+00,  1.3049e+00,  8.3030e-01,  9.6273e-01,\n",
            "            1.1614e+00,  8.4133e-01,  4.2195e-01,  5.9854e-01,  3.3366e-01,\n",
            "           -4.6095e-01, -6.1546e-01, -1.2004e+00, -1.1452e+00, -1.5867e+00,\n",
            "            3.5684e-02, -4.1570e-02,  7.5304e-01, -2.5126e-01, -7.6997e-01]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL1-73.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.6645, -0.4430, -1.5506, -1.4399, -0.2215, -0.8861,  0.8861,\n",
            "            2.3259,  0.9968,  0.6645, -2.4367,  0.2215,  0.5538,  1.5506,\n",
            "            1.1076, -1.3291, -0.5538,  0.6645, -0.4430, -0.3323, -0.5538,\n",
            "           -0.1108,  0.5538, -0.7753,  0.1108,  0.8861,  0.1108, -0.6645,\n",
            "            0.4430,  0.0000],\n",
            "          [-0.8703, -2.0054,  1.6838, -0.5865, -0.7757,  1.1162,  1.2108,\n",
            "           -0.7757, -1.0595,  0.5487, -0.4919, -1.0595, -1.6271,  1.2108,\n",
            "           -0.4919,  0.2649,  0.8324, -0.2081, -0.3027,  0.0757,  1.5892,\n",
            "            0.6433,  0.2649, -1.1541,  1.7784, -0.0189, -0.4919,  1.1162,\n",
            "           -0.2081, -0.2081],\n",
            "          [-0.2747, -0.2747,  1.4735,  0.7243,  1.1405, -1.2737,  0.0583,\n",
            "           -0.5245,  0.1415,  0.8908, -0.0250,  0.7243,  1.3903, -0.4412,\n",
            "            0.6410, -0.1915,  0.6410, -0.2747,  1.4735,  0.3913, -1.2737,\n",
            "           -0.6910, -0.6910,  1.1405,  0.8908, -0.5245,  0.1415, -1.7732,\n",
            "           -2.6890, -0.9407],\n",
            "          [ 0.3265, -0.2117, -0.2117,  0.0036, -1.0728, -0.2117, -1.0728,\n",
            "           -0.1041, -1.0728,  0.0036, -0.1041, -0.4270, -0.8575,  0.1112,\n",
            "            1.8335,  0.6494,  1.0800,  1.0800, -1.1804, -0.4270,  0.9723,\n",
            "           -0.8575, -1.0728, -0.1041,  0.8647,  0.0036,  1.1876,  2.4793,\n",
            "            0.6494, -2.2568],\n",
            "          [ 0.8210,  0.5118,  1.5423,  1.0270,  1.4392,  1.1301, -1.2400,\n",
            "            1.7484, -0.3126,  0.0996,  0.6149,  0.9240, -0.0034, -1.0339,\n",
            "           -0.0034, -0.6217, -2.0644, -0.5187,  1.2331, -0.3126,  0.7179,\n",
            "           -1.0339, -0.3126, -0.2095, -1.1370,  0.8210, -0.5187, -1.1370,\n",
            "           -1.3431, -0.8278],\n",
            "          [-0.4441,  0.9479, -0.7424, -0.6430,  0.7490,  1.6439,  1.8427,\n",
            "           -0.2453,  0.8485,  0.5502,  0.0530,  0.4507, -1.5378,  0.8485,\n",
            "           -0.3447, -0.4441,  1.2462, -0.4441, -2.4327,  0.0530,  1.0473,\n",
            "           -0.1458, -0.2453, -1.3390,  0.0530,  1.3456, -1.2395, -0.2453,\n",
            "           -1.2395,  0.0530],\n",
            "          [-0.8144, -0.9617, -1.0280, -0.7702, -1.2491, -0.9028, -0.5418,\n",
            "           -0.9396, -0.5933, -0.7407, -0.7112, -0.6007, -0.8807, -0.6818,\n",
            "            0.2024, -0.0555, -0.1808, -0.7849,  0.1508,  0.2392,  0.2834,\n",
            "            0.3350,  0.6813,  0.7476,  1.2044,  1.8896,  0.9760,  2.2948,\n",
            "            1.9190,  1.5138],\n",
            "          [-1.2127, -1.6093, -1.7018, -1.0144, -0.4856, -0.7368, -0.5517,\n",
            "           -1.2391, -0.0890, -0.3534, -0.8425, -0.4856, -0.5253, -0.3138,\n",
            "           -0.5781, -0.5253,  0.1357,  0.1093,  0.7571, -0.2873,  0.7571,\n",
            "            1.4180,  1.6428,  0.6777,  0.4530,  0.5191,  1.8543,  1.4841,\n",
            "            1.2594,  1.4841],\n",
            "          [ 0.4848,  1.8725, -1.6622, -0.5756,  0.8121, -1.8585, -0.8636,\n",
            "           -0.4578,  0.4717,  0.3408,  0.2754,  0.1313,  1.4143,  0.6812,\n",
            "            0.7990,  0.4455, -2.0287,  1.6107, -0.2221, -0.3792, -0.9421,\n",
            "           -2.0418, -0.3530, -0.2876,  0.3539,  0.2230,  0.6681,  0.0266,\n",
            "            0.6026,  0.4586],\n",
            "          [-0.0043,  0.2511, -0.5150, -1.0257,  1.2725, -0.2596, -0.7703,\n",
            "            1.2725, -0.5150, -0.6426, -0.6426, -1.9194, -0.6426, -0.8980,\n",
            "           -1.5364,  0.6341, -0.6426,  1.2725, -0.1319, -0.0043,  1.4002,\n",
            "            1.7832, -1.0257,  1.7832, -0.2596,  1.5279, -0.2596, -0.6426,\n",
            "            0.6341,  0.5065],\n",
            "          [ 1.1303,  1.3751,  1.8647,  0.8854,  0.3958,  0.2734,  1.3751,\n",
            "           -0.0938,  0.6406,  1.2527, -0.2163,  1.0078, -0.2163,  1.0078,\n",
            "           -0.4611, -1.1955,  0.1510, -0.9507, -0.2163,  0.1510, -1.3179,\n",
            "            0.3958, -1.3179, -0.4611, -0.2163, -0.0938, -1.3179, -1.3179,\n",
            "           -2.2972, -0.2163],\n",
            "          [ 1.3931, -1.5380,  0.3530,  1.4876, -0.9707,  0.1639,  0.8257,\n",
            "           -0.0252,  2.4331,  0.5421,  0.8257,  0.0693, -0.0252, -1.7271,\n",
            "           -0.0252, -0.6871,  1.0149, -1.6326,  0.1639,  0.2584, -1.4435,\n",
            "            0.0693, -0.9707,  0.6366, -0.4034, -1.0653, -0.0252,  1.0149,\n",
            "           -0.8762,  0.1639],\n",
            "          [ 1.0874,  0.5597,  0.7996,  0.6396,  0.7196,  1.1194,  0.9115,\n",
            "            0.8155,  0.5117,  0.1599,  0.6396,  0.6716,  0.0800,  0.1759,\n",
            "            0.1759,  0.5597,  0.5757,  0.1919,  0.4797,  0.0160, -0.2239,\n",
            "            0.0000,  0.0000, -0.0480, -1.5192, -0.8155, -1.4552, -1.8710,\n",
            "           -2.2228, -2.7345],\n",
            "          [-0.9598, -0.9294, -0.9294, -1.0663, -0.9142, -0.9446, -1.0815,\n",
            "           -0.9903, -0.7165, -0.8534, -0.9294, -0.8838, -0.5643, -0.5035,\n",
            "           -0.1993,  0.0137, -0.1080,  0.2267, -0.0624,  0.2267, -0.0319,\n",
            "            0.7895,  0.9112,  1.0633,  1.2610,  1.5653,  1.5653,  1.4436,\n",
            "            1.6109,  1.9912],\n",
            "          [-1.2901, -1.4540, -1.2198, -0.8451, -0.8568, -1.0090, -1.0442,\n",
            "           -0.7983, -0.6812, -0.6109, -0.5758, -0.7514, -0.6929, -0.2713,\n",
            "           -0.1776, -0.0956, -0.2596,  0.1737,  0.3494,  0.4899,  0.5601,\n",
            "            0.2440,  0.5367,  0.8061,  1.1574,  1.2511,  1.6258,  1.8600,\n",
            "            1.6726,  1.9068]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-105.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[-1.1585e+00, -1.0890e+00, -9.8488e-01, -1.1585e+00, -8.1128e-01,\n",
            "           -1.1238e+00, -2.1133e+00, -1.3494e+00, -9.9529e-02, -6.7240e-01,\n",
            "           -1.0543e+00, -5.6824e-01, -5.3352e-01, -4.2937e-01,  1.0636e+00,\n",
            "           -4.6408e-01,  6.2958e-01,  3.8654e-01,  7.1638e-01,  6.9902e-01,\n",
            "            8.7262e-01,  9.5942e-01,  1.3240e+00,  6.4694e-01,  1.0983e+00,\n",
            "            9.9414e-01,  8.7262e-01,  1.4108e+00,  1.0636e+00,  8.7262e-01],\n",
            "          [-8.0961e-01, -1.3655e+00, -7.1294e-01, -6.1627e-01, -5.1960e-01,\n",
            "           -1.2930e+00, -9.3045e-01, -8.3378e-01, -4.7127e-01, -1.4380e+00,\n",
            "           -1.9213e+00, -1.4621e+00, -5.4377e-01,  3.6251e-02,  1.3655e+00,\n",
            "           -4.9543e-01,  1.0755e+00,  9.0628e-01,  1.0755e+00,  8.8212e-01,\n",
            "            1.1963e+00,  2.0542e-01,  8.5795e-01,  9.7879e-01,  9.0628e-01,\n",
            "            6.6461e-01,  1.0996e+00,  9.0628e-01,  1.0755e+00,  1.8126e-01],\n",
            "          [ 1.1799e+00,  9.7443e-01,  9.1573e-01,  9.8910e-01,  8.8638e-01,\n",
            "            1.0918e+00,  9.4508e-01,  8.1300e-01,  7.3962e-01,  1.0038e+00,\n",
            "            3.5807e-01,  8.2768e-01,  7.5430e-01,  2.4067e-01,  8.5703e-01,\n",
            "            2.8470e-01, -2.3421e+00, -1.7111e+00, -1.0654e+00, -1.0801e+00,\n",
            "           -1.4470e+00, -1.2268e+00, -1.1094e+00, -1.1535e+00, -5.8113e-01,\n",
            "           -1.5556e-01, -3.1698e-01, -1.5556e-01, -3.0231e-01, -2.1426e-01],\n",
            "          [-8.9570e-01, -9.0847e-01, -8.0625e-01, -8.2542e-01, -9.8514e-01,\n",
            "           -9.5958e-01, -9.2764e-01, -7.5515e-01, -6.9765e-01, -8.1264e-01,\n",
            "           -1.0299e+00, -9.2125e-01, -9.4681e-01, -9.0847e-01, -1.0171e+00,\n",
            "           -1.1512e+00,  7.3342e-01,  8.3564e-01,  9.5064e-01,  1.0273e+00,\n",
            "            1.2254e+00,  1.2573e+00,  1.0784e+00,  1.0848e+00,  8.7398e-01,\n",
            "            8.1009e-01,  9.3147e-01,  1.1870e+00,  1.3404e+00,  1.2126e+00],\n",
            "          [ 8.9018e-01,  7.7630e-01,  8.2185e-01,  8.7879e-01,  8.1046e-01,\n",
            "            1.1407e+00,  1.1407e+00,  9.2434e-01,  8.6740e-01,  7.1935e-01,\n",
            "            1.0610e+00,  9.6990e-01,  8.7879e-01,  9.1295e-01,  7.8768e-01,\n",
            "            7.8768e-01, -6.1306e-01, -7.0417e-01, -9.3193e-01, -9.4332e-01,\n",
            "           -9.5471e-01, -1.1711e+00, -9.5471e-01, -5.9029e-01, -8.1805e-01,\n",
            "           -1.1825e+00, -1.4330e+00, -1.4672e+00, -1.1939e+00, -1.4102e+00],\n",
            "          [-7.8747e-01, -9.1397e-01, -8.7444e-01, -8.6653e-01, -7.0050e-01,\n",
            "           -1.0088e+00, -9.3769e-01, -7.6375e-01, -8.8235e-01, -8.5072e-01,\n",
            "           -1.0168e+00, -9.8513e-01, -9.6141e-01, -1.0958e+00, -9.2978e-01,\n",
            "           -8.4281e-01,  5.9614e-01,  8.6495e-01,  9.2030e-01,  1.0784e+00,\n",
            "            1.1575e+00,  1.1654e+00,  1.0073e+00,  6.4358e-01,  7.0683e-01,\n",
            "            8.4914e-01,  1.3710e+00,  1.3710e+00,  1.2366e+00,  1.4500e+00],\n",
            "          [ 6.5059e-01,  6.6644e-01,  6.6248e-01,  7.2986e-01,  3.1763e-01,\n",
            "           -1.1838e-01,  1.8683e-01,  7.5840e-02, -7.4466e-01, -1.3472e+00,\n",
            "           -1.2045e+00, -1.1926e+00, -1.3630e+00, -1.5850e+00, -2.2113e+00,\n",
            "           -2.5165e+00,  7.0608e-01,  8.0517e-01,  8.4481e-01,  5.8320e-01,\n",
            "            7.9328e-01,  6.5059e-01,  4.0880e-01,  7.2193e-01,  8.8841e-01,\n",
            "            4.5240e-01,  5.9906e-01,  6.9419e-01,  5.5942e-01,  2.8592e-01],\n",
            "          [ 2.2110e+00,  1.7126e+00,  1.4633e+00,  8.4620e-01,  5.3763e-01,\n",
            "            2.1125e-01, -3.2281e-01, -7.2040e-01, -9.3403e-01, -1.2901e+00,\n",
            "           -1.2011e+00, -1.2248e+00, -1.2426e+00, -1.2129e+00, -8.9249e-01,\n",
            "           -6.4919e-01, -7.1446e-01, -6.1359e-01, -5.4831e-01, -4.8304e-01,\n",
            "           -4.4743e-01, -2.6347e-01, -8.3077e-03,  3.9521e-01,  2.9433e-01,\n",
            "            5.4356e-01,  7.2752e-01,  1.3625e+00,  1.2616e+00,  1.2022e+00],\n",
            "          [ 1.1161e+00,  9.9346e-01,  5.1117e-01,  6.9755e-02, -4.1254e-01,\n",
            "           -1.4343e+00, -1.5815e+00, -1.3281e+00, -1.4425e+00, -1.2954e+00,\n",
            "           -5.2698e-01,  3.7057e-02,  9.8529e-01,  1.4104e+00,  1.4431e+00,\n",
            "            1.6556e+00, -1.9003e+00, -1.3608e+00, -6.0872e-01,  2.0872e-01,\n",
            "            3.3951e-01, -1.3461e-01, -2.2452e-01,  4.5395e-01,  5.5205e-01,\n",
            "            1.9237e-01,  4.7030e-01,  8.2180e-01,  1.8420e-01,  8.0545e-01],\n",
            "          [ 6.9908e-01,  9.0163e-01,  1.1410e+00,  8.8322e-01,  1.0305e+00,\n",
            "            9.0163e-01,  8.6480e-01,  6.8067e-01,  7.1750e-01,  1.0305e+00,\n",
            "            9.0163e-01,  1.0305e+00,  8.6480e-01,  7.9115e-01,  8.8322e-01,\n",
            "            1.2699e+00, -9.9492e-01, -1.0133e+00, -9.9492e-01, -1.0686e+00,\n",
            "           -1.2527e+00, -9.9492e-01, -1.0317e+00, -9.5810e-01, -1.0686e+00,\n",
            "           -1.1054e+00, -9.2127e-01, -9.3968e-01, -1.1054e+00, -1.1422e+00],\n",
            "          [-1.1898e+00, -1.1898e+00, -1.2579e+00, -9.5138e-01, -6.4485e-01,\n",
            "           -2.7020e-01, -2.7020e-01,  7.0388e-02, -5.7673e-01,  2.0662e-01,\n",
            "            6.4939e-01,  8.1968e-01,  9.8998e-01,  1.3306e+00,  2.3183e+00,\n",
            "            2.8292e+00,  6.8345e-01,  4.4504e-01,  2.2706e-03, -6.5847e-02,\n",
            "           -1.3396e-01,  1.3851e-01,  2.7474e-01, -3.1788e-02,  4.4504e-01,\n",
            "           -8.1514e-01, -1.2238e+00, -1.1557e+00, -6.1079e-01, -8.1514e-01],\n",
            "          [ 5.3133e-01,  6.1533e-01,  7.3434e-01,  6.9934e-01,  7.6234e-01,\n",
            "            9.0935e-01,  7.3434e-01,  6.5034e-01,  9.3735e-01,  1.0564e+00,\n",
            "            9.9336e-01,  1.0844e+00,  1.0214e+00,  1.0424e+00,  1.2734e+00,\n",
            "            1.3434e+00, -7.4974e-01, -7.7074e-01, -7.8474e-01, -9.5275e-01,\n",
            "           -1.0718e+00, -9.8776e-01, -9.1775e-01, -1.0578e+00, -1.0858e+00,\n",
            "           -1.0088e+00, -1.2118e+00, -1.3448e+00, -1.1978e+00, -1.2468e+00],\n",
            "          [-9.7561e-01, -1.1071e+00, -1.6250e+00, -6.4895e-01,  4.8641e-01,\n",
            "            3.8682e-01,  7.0551e-01,  1.6337e+00,  2.1596e+00,  1.4305e+00,\n",
            "            9.6446e-01,  7.7324e-01,  1.8763e-01,  1.1875e+00,  1.4345e+00,\n",
            "            1.3708e+00,  3.7088e-01, -3.3822e-01, -4.9757e-01, -8.2821e-01,\n",
            "           -8.7602e-01, -2.8643e-01, -5.3342e-01, -1.0154e+00, -6.8082e-01,\n",
            "           -7.6846e-01, -8.5610e-01, -8.4016e-01, -5.4935e-01, -6.6488e-01],\n",
            "          [ 1.3001e+00,  1.3559e+00,  7.1703e-01,  3.2006e-01, -9.5522e-02,\n",
            "           -1.0793e-01, -4.8629e-01, -1.0073e+00, -1.4787e+00, -9.5770e-01,\n",
            "           -1.4167e+00, -1.6958e+00, -1.4167e+00, -1.0880e+00, -7.2200e-01,\n",
            "            9.9243e-03, -4.9250e-01, -4.1186e-01, -5.5452e-01, -4.8629e-01,\n",
            "            1.8360e-01,  1.8980e-01,  2.2702e-01,  2.5803e-01,  8.4109e-01,\n",
            "            1.2753e+00,  1.6785e+00,  1.5916e+00,  1.2877e+00,  1.1822e+00],\n",
            "          [ 7.3734e-01,  5.0574e-01,  5.6810e-01,  6.9874e-01,  6.9874e-01,\n",
            "            5.7700e-01,  4.0776e-01,  1.5538e-01, -1.5637e-01, -5.9878e-01,\n",
            "           -9.3132e-01, -1.2075e+00, -1.9052e+00, -2.1516e+00, -2.3743e+00,\n",
            "           -2.2852e+00,  8.5016e-01,  7.8781e-01,  8.4423e-01,  5.2950e-01,\n",
            "            3.6026e-01,  4.2261e-01,  7.7297e-01,  8.0266e-01,  9.6002e-02,\n",
            "            3.2166e-01,  2.9790e-01,  3.6026e-01,  4.1964e-01,  3.9589e-01]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-119.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 9.3278e-01,  1.1388e+00,  4.5208e-01, -4.4064e-01, -5.0931e-01,\n",
            "            1.4306e-01,  1.3963e+00,  1.0873e+00,  7.7827e-01,  1.0701e+00,\n",
            "            3.8341e-01, -4.0630e-01,  5.0359e-01,  1.0358e+00,  6.9243e-01,\n",
            "            3.4908e-01,  5.7226e-03,  2.2890e-02,  2.2890e-02,  2.6324e-01,\n",
            "            3.4908e-01,  5.0359e-01,  7.9544e-01, -8.8700e-01, -8.1833e-01,\n",
            "           -2.2261e+00, -2.1574e+00, -1.7454e+00, -1.1445e+00, -1.5909e+00],\n",
            "          [ 1.3247e+00,  2.1636e+00,  3.5807e-01,  4.4926e-01,  1.8536e+00,\n",
            "            1.3429e+00,  4.3103e-01, -3.8969e-01, -1.5259e-01, -2.8026e-01,\n",
            "           -3.3497e-01, -3.3497e-01, -1.7083e-01, -2.8026e-01, -4.8088e-01,\n",
            "           -3.1673e-01, -7.9639e-02,  3.5807e-01,  1.1551e-02,  3.7631e-01,\n",
            "            1.3794e+00,  4.3103e-01, -9.7877e-02,  3.2160e-01, -4.3163e-02,\n",
            "           -9.5507e-01, -1.7758e+00, -1.1739e+00, -1.6299e+00, -2.3047e+00],\n",
            "          [ 2.8223e-01,  5.8994e-01,  9.8995e-01,  1.1284e+00,  1.1797e+00,\n",
            "            9.9508e-01,  1.0823e+00,  9.6431e-01,  1.0976e+00,  9.4893e-01,\n",
            "            1.0566e+00,  6.4122e-01,  5.3352e-01,  4.6173e-01,  2.6172e-01,\n",
            "            2.5659e-01,  5.1455e-02, -8.7012e-02, -2.4086e-01, -3.3318e-01,\n",
            "           -3.0240e-01, -3.9472e-01, -7.4345e-01, -1.0717e+00, -1.2563e+00,\n",
            "           -1.1024e+00, -1.2409e+00, -1.6819e+00, -1.9537e+00, -2.1127e+00],\n",
            "          [-1.1751e+00, -3.9129e-01, -6.2552e-01, -6.3453e-01, -2.9219e-01,\n",
            "           -1.7507e-01, -8.4984e-02,  3.2943e-01,  1.7889e+00,  6.0870e-01,\n",
            "           -5.7957e-02, -1.6796e+00,  3.0051e+00, -5.9849e-01,  1.3204e+00,\n",
            "           -1.1120e+00,  1.2303e+00,  1.8880e+00,  2.4835e-01, -7.6966e-01,\n",
            "           -3.1021e-01, -2.1922e-02,  5.1050e-03, -1.7507e-01, -3.7327e-01,\n",
            "           -2.4714e-01, -1.0300e-01, -1.1751e+00, -4.7237e-01,  5.0150e-02],\n",
            "          [-4.8662e-02,  2.1733e-01,  1.6784e-01,  3.9054e-01,  8.4829e-01,\n",
            "            7.0602e-01,  8.9778e-01,  2.0669e+00,  1.9246e+00,  1.3184e+00,\n",
            "            1.3432e+00,  1.8022e-01,  6.4416e-01, -1.2054e+00, -2.2818e+00,\n",
            "           -1.8055e+00, -1.0013e+00, -7.4148e-01,  7.0602e-01,  3.7940e-02,\n",
            "           -7.9592e-02, -7.2292e-01,  1.1217e-01, -1.1052e-01, -3.3940e-01,\n",
            "           -5.1879e-01, -5.4972e-01, -6.3632e-01, -8.2190e-01, -6.9818e-01],\n",
            "          [ 1.6262e+00,  1.3224e+00,  1.3052e+00,  1.3956e+00,  1.2599e+00,\n",
            "            1.2836e+00,  1.0531e+00,  8.9797e-01,  1.2384e+00,  1.1522e+00,\n",
            "            6.0712e-01,  2.6456e-01,  3.0119e-01, -5.4292e-02, -4.9811e-01,\n",
            "           -8.2989e-01, -1.0216e+00, -4.6363e-01, -7.0062e-01, -5.0888e-01,\n",
            "           -7.8034e-01, -7.8249e-01, -8.1912e-01, -9.1176e-01, -9.5485e-01,\n",
            "           -1.0453e+00, -1.1918e+00, -9.3330e-01, -1.1380e+00, -1.0733e+00],\n",
            "          [-1.5077e+00, -2.2937e+00, -1.3481e+00, -3.0417e-01, -1.8884e+00,\n",
            "           -8.6910e-01, -8.6910e-01, -1.1884e+00, -4.5154e-01,  1.5024e-01,\n",
            "           -2.3048e-01, -1.4451e-01, -3.0417e-01, -2.7960e-01, -1.9363e-01,\n",
            "           -9.4156e-03,  2.8533e-01,  9.6080e-01,  1.4152e+00,  1.2801e+00,\n",
            "            7.7658e-01,  1.3292e+00,  7.6430e-01,  9.4852e-01, -7.0822e-02,\n",
            "            3.4674e-01,  7.8886e-01,  1.1450e+00,  1.3538e+00,  4.0815e-01],\n",
            "          [-1.4147e+00, -1.3968e+00, -1.0476e+00, -1.0476e+00, -1.0656e+00,\n",
            "           -5.5530e-01, -4.6579e-01, -3.8522e-01, -9.8767e-02,  3.3987e-01,\n",
            "            2.3245e-01,  2.5930e-01, -1.8202e-02,  2.2349e-01,  1.6083e-01,\n",
            "            6.4422e-01,  1.0381e+00,  1.0381e+00,  8.7697e-01,  1.1097e+00,\n",
            "            1.6379e+00,  2.1213e+00,  1.6379e+00,  8.4116e-01,  3.4882e-01,\n",
            "           -5.4635e-01, -1.0656e+00, -8.7756e-01, -1.4415e+00, -1.0835e+00],\n",
            "          [ 1.8885e+00,  1.5369e+00,  1.6097e+00,  8.9436e-01,  2.2644e+00,\n",
            "            1.1490e+00,  3.4877e-01,  7.6100e-01,  2.5178e-01, -1.6044e-01,\n",
            "            5.7792e-02,  3.2452e-01,  1.7903e-01, -1.3620e-01, -4.3930e-01,\n",
            "           -9.4852e-01,  3.4877e-01, -1.3620e-01, -4.7567e-01, -8.0303e-01,\n",
            "           -3.1806e-01, -3.3018e-01, -1.7002e+00, -6.8179e-01, -3.0593e-01,\n",
            "           -5.8479e-01, -3.3018e-01, -1.4456e+00, -1.4699e+00, -1.3486e+00],\n",
            "          [ 3.2003e-01,  7.0707e-01,  3.0755e-01, -2.9548e-02, -4.0410e-01,\n",
            "            3.2003e-01, -9.9089e-01, -7.7865e-01, -7.7865e-01, -1.0533e+00,\n",
            "           -5.1646e-01, -1.7774e+00,  7.0707e-01, -3.6664e-01,  1.1440e+00,\n",
            "           -8.2859e-01, -2.3393e+00, -1.2943e-01,  2.2302e+00,  4.4488e-01,\n",
            "            5.5725e-01,  1.0691e+00,  1.2814e+00,  1.3937e+00,  1.1066e+00,\n",
            "            1.4524e-01,  1.7021e-01, -3.0422e-01, -4.0410e-01, -1.2031e+00],\n",
            "          [ 1.3255e-01, -1.8061e-01,  1.3255e-01,  2.9277e-01,  4.4571e-01,\n",
            "            3.9473e-01,  5.6952e-01,  8.8996e-01,  1.6401e+00,  5.9137e-01,\n",
            "            2.3451e-01, -6.6128e-01, -1.5279e+00, -1.8702e+00, -2.3655e+00,\n",
            "           -1.1856e+00,  6.2778e-01,  1.5017e+00,  1.7493e+00,  1.1084e+00,\n",
            "            2.4179e-01,  1.2526e-01,  3.9473e-01,  4.3843e-01,  8.8851e-02,\n",
            "           -3.8453e-01, -5.0834e-01, -6.5400e-01, -7.7781e-01, -1.4842e+00],\n",
            "          [-1.3873e+00, -1.3458e+00, -1.2848e+00, -1.3829e+00, -1.3087e+00,\n",
            "           -1.0339e+00, -1.3415e+00, -1.3589e+00, -8.7691e-01, -9.1399e-01,\n",
            "           -8.9654e-01, -5.0396e-01, -4.0581e-01,  3.6626e-01,  4.9712e-01,\n",
            "            5.8873e-01,  8.6571e-01,  6.2144e-01,  6.4761e-01,  8.1337e-01,\n",
            "            8.1991e-01,  6.4325e-01,  8.0901e-01,  1.0838e+00,  1.0315e+00,\n",
            "            1.0533e+00,  1.0118e+00,  1.0751e+00,  1.0315e+00,  1.0816e+00],\n",
            "          [ 1.3659e+00,  1.5987e+00,  1.7763e-01,  1.0719e+00,  1.4272e+00,\n",
            "            1.2189e+00,  7.2890e-01,  9.1265e-01, -5.6964e-01,  5.3289e-01,\n",
            "           -5.4514e-01, -8.6365e-01,  6.1252e-03, -6.1252e-03,  9.1878e-02,\n",
            "           -3.2463e-01, -1.2189e+00, -1.4639e+00, -2.2234e+00, -2.5113e-01,\n",
            "           -1.1944e+00, -1.1822e+00, -3.2463e-01, -4.2264e-01,  1.8376e-02,\n",
            "           -8.5140e-01, -7.2890e-01,  1.0107e+00,  1.5987e+00,  4.1039e-01],\n",
            "          [-1.7606e+00, -1.7875e+00, -7.3094e-01, -1.2861e+00, -4.9814e-01,\n",
            "           -3.7278e-01,  2.1191e-02, -1.2207e-01,  5.4052e-01,  6.5961e-02,\n",
            "            4.5098e-01, -1.4625e-02, -2.3579e-02,  1.4655e-01,  8.5391e-01,\n",
            "            5.0470e-01,  4.0621e-01,  6.1215e-01,  1.0061e+00,  9.3449e-01,\n",
            "            1.5434e+00,  2.2418e+00,  1.7493e+00,  6.8378e-01, -1.4893e-01,\n",
            "           -1.0891e+00, -1.1697e+00, -6.2349e-01, -1.1249e+00, -1.0085e+00],\n",
            "          [-6.6527e-01,  9.6104e-01,  1.6740e-01,  8.8298e-01, -7.6935e-01,\n",
            "           -6.9129e-01, -5.6119e-01, -5.4817e-01,  5.0307e-02,  7.7889e-01,\n",
            "            2.5847e-01,  4.5363e-01, -1.7347e-03,  6.3318e-02, -1.0556e+00,\n",
            "           -6.6527e-01, -1.0582e-01, -2.0990e-01, -6.0022e-01, -1.7087e-01,\n",
            "           -8.7344e-01, -1.3028e+00, -1.2377e+00, -1.4719e+00, -5.3516e-01,\n",
            "            1.8041e-01,  1.3644e+00,  1.4424e+00,  2.5093e+00,  2.3532e+00]]]],\n",
            "       device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-54.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n",
            "tensor([[[[ 0.6547,  0.1325,  0.8154,  0.2397, -0.2557, -0.9519, -0.0415,\n",
            "            0.2129,  0.1325, -1.4607, -2.1569, -1.3402, -1.6347, -1.0724,\n",
            "           -0.5369, -1.1126, -0.7913, -0.6975, -0.0281, -0.0281,  0.2932,\n",
            "            0.4673,  1.1233,  1.1233,  0.8555,  1.2840,  1.1099,  0.5208,\n",
            "            1.7927,  1.3509],\n",
            "          [ 1.2135,  1.7870, -0.7193, -0.8255,  0.2577, -0.2945, -0.9530,\n",
            "            0.7887,  0.6188, -1.0592, -0.8255, -0.1671, -1.2503, -1.7176,\n",
            "           -1.4202, -1.9725, -0.5706, -0.1458,  0.7037,  1.0648,  1.0861,\n",
            "            0.5338, -0.1458,  0.5126,  0.8737,  1.4259,  0.2152, -0.8043,\n",
            "            0.8737,  0.9161],\n",
            "          [-1.3405, -1.2197, -1.2901, -1.4713, -1.3908, -0.7969, -0.4546,\n",
            "           -0.8774, -1.0485, -0.4949, -0.2332, -0.5452, -0.3741, -0.7566,\n",
            "           -0.4345, -0.1426, -0.2332, -0.0117,  0.4211,  0.7533,  1.1861,\n",
            "            0.8741,  0.9747,  0.7130,  1.4881,  1.1861,  1.5082,  1.2163,\n",
            "            1.3170,  1.4780],\n",
            "          [-0.5024,  0.7040,  1.2647,  1.1883,  1.0608,  1.0184,  1.2053,\n",
            "            1.1288,  0.6021,  0.3642,  0.1008, -0.0606, -0.1286, -0.3749,\n",
            "           -0.7997, -0.5364, -0.5364, -0.0351, -0.5449, -0.0691, -0.9527,\n",
            "            0.7380, -2.0231, -3.1446,  0.6445, -0.6383, -0.9442,  0.7720,\n",
            "            0.6361, -0.1371],\n",
            "          [-0.7517, -0.9875, -1.2447, -1.8664, -1.9842, -1.5127, -1.0304,\n",
            "           -0.9017, -0.4087,  0.1058, -0.4194, -0.0550,  0.1486,  0.0414,\n",
            "            0.1486,  0.4487,  0.4809,  1.0918,  0.9203,  0.3737,  1.8313,\n",
            "            0.7060,  0.1808, -0.3766,  0.6202,  1.6063, -0.4194,  0.6631,\n",
            "            1.7134,  0.8774],\n",
            "          [ 0.0742,  0.2621,  0.4704,  0.5684,  0.5889,  0.4704,  0.3724,\n",
            "            0.6256,  0.6256,  0.7972,  1.0218,  1.0831,  1.0790,  1.2097,\n",
            "            0.8585,  0.6461,  0.7318,  0.4990,  0.2784,  0.1845, -0.4527,\n",
            "           -0.7182, -1.4126, -2.2173, -2.0294, -1.9436, -0.4976, -1.1103,\n",
            "           -1.3636, -0.7019],\n",
            "          [ 0.0988, -0.0546,  0.1479, -0.6378, -0.3554, -1.1411, -0.7790,\n",
            "           -0.5641, -0.9079, -0.2081,  0.4119, -0.2818, -0.5273, -1.2578,\n",
            "           -1.6813, -1.6015, -1.4665, -0.8588, -0.1835,  0.5101,  1.5598,\n",
            "            1.3388,  0.8784,  1.1055,  1.5720,  1.4677,  1.4554,  1.1424,\n",
            "            0.5715,  0.2462],\n",
            "          [-0.7010,  0.0322,  0.2868,  0.1634, -0.8245, -1.0020, -1.3339,\n",
            "           -1.9282, -0.8708,  0.2946,  1.3365,  1.4677,  0.7268,  0.1788,\n",
            "           -0.6393, -1.7892, -1.6735, -1.1024, -0.7087,  0.0707,  1.0200,\n",
            "            1.1358,  1.2438,  1.2824,  1.0432,  0.6882,  0.4258,  0.3100,\n",
            "            0.4644,  0.4026],\n",
            "          [-0.6375, -0.2409,  0.1462,  0.8344,  1.5465,  1.1211,  2.2633,\n",
            "            2.4640,  1.7137,  0.9826,  0.3374, -0.4894,  0.1271,  0.0220,\n",
            "           -0.4559, -1.0772, -0.9338, -0.3986, -0.2074, -0.4129, -0.0210,\n",
            "           -0.1787, -0.3747, -0.3699, -0.5419, -0.8908, -1.1250, -1.0198,\n",
            "           -1.0389, -1.1441],\n",
            "          [ 0.1472,  0.1381, -0.1981, -0.6342, -0.9431, -1.0612, -1.3156,\n",
            "           -1.4337, -1.4337, -1.3156, -1.0430, -0.6978, -0.0618, -0.1436,\n",
            "           -0.5070,  0.0563,  0.3562,  0.2108,  0.1199, -0.3343,  0.4016,\n",
            "           -0.1345,  0.2835,  0.7650,  1.9461,  2.2187,  1.8916,  1.1284,\n",
            "            1.5373,  0.0563],\n",
            "          [-0.6000, -0.7967, -0.9328, -1.0842, -1.2733, -1.5759, -1.6894,\n",
            "           -1.5532, -1.1069, -0.6605, -0.2368, -0.2444, -0.2292, -0.0174,\n",
            "            0.0129,  0.1415,  0.2625,  0.2852,  0.3609,  0.5122,  0.2777,\n",
            "            0.3457,  0.8451,  0.5122,  0.7997,  0.9359,  1.3141,  1.9270,\n",
            "            1.8967,  1.5714],\n",
            "          [ 1.5477,  1.3093,  0.9121,  0.4274,  0.1573, -0.0890, -0.0731,\n",
            "           -0.5419, -0.4624, -0.1843, -0.4227, -0.5339, -1.0186, -1.3125,\n",
            "           -1.1695, -0.9947, -1.1060, -1.2410, -0.8835, -0.6451, -0.8914,\n",
            "           -0.4783, -0.3909, -0.1843,  0.8883,  1.9449,  1.6430,  1.1902,\n",
            "            1.7860,  0.8168],\n",
            "          [-0.1107, -0.4098, -0.1481,  0.3422, -0.2852, -0.4015, -0.3724,\n",
            "           -0.8835, -0.9707, -0.7339,  0.1303,  1.3311,  2.2411,  2.5901,\n",
            "            2.1829,  1.3685,  0.5666, -0.1771, -0.8669, -1.0206, -0.8960,\n",
            "           -0.9043, -0.9417, -0.8586, -0.5677, -0.3059, -0.1730, -0.0151,\n",
            "            0.1096,  0.1802],\n",
            "          [-0.3463, -0.7197, -1.2573, -1.6250, -2.0268, -2.7793, -1.4044,\n",
            "           -0.3972,  0.8023,  0.4232, -0.0181, -0.0238,  0.1912,  0.0837,\n",
            "           -0.1482, -0.1313,  0.2988,  0.8872,  1.2550,  1.5436,  1.3568,\n",
            "            0.8306,  0.9155,  0.7684,  0.3440,  0.1007,  0.0951,  0.2252,\n",
            "            0.3327,  0.4232],\n",
            "          [-0.5685, -1.1117, -1.6930, -0.7622, -1.8931, -1.9217, -1.1974,\n",
            "           -1.0386, -0.6447, -0.0793,  0.1240, -0.1905, -0.5844, -0.5780,\n",
            "           -0.2667, -0.1047,  0.0541,  0.3368,  0.6608,  0.7783,  1.0229,\n",
            "            1.2707,  1.2675,  1.2580,  1.2516,  1.2135,  0.9626,  0.9372,\n",
            "            0.7688,  0.7275]]]], device='cuda:0')\n",
            "tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]],\n",
            "\n",
            "         [[nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          ...,\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan],\n",
            "          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\n",
            "dataset_parsed/train/S3-ADL5-161.csv\n",
            "None tensor([[[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]],\n",
            "\n",
            "\n",
            "        [[[nan, nan, nan, nan, nan]]]], device='cuda:0')\n",
            "None tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-10250c72ec9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#for data, labels in log_progress(dataloader_train, name=\"Training\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m#print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtrain_losses_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-16b8477f7f1d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-16b8477f7f1d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#print(.parameters().data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'{{:.{}f}}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDrbO1atgtc5",
        "outputId": "458d847f-b0c9-4cc8-a504-239d973f7c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, nan, nan, nan, nan, nan]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5c-2WTkBw8t",
        "outputId": "01f4d8b5-fbab-453c-d9bf-b574bf77081e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439,
          "referenced_widgets": [
            "99c64156779342b39bad78d14c13686a",
            "c4aa60eeee044e4fa329b5d0dd70a665",
            "ce76a8f16b144eb8b8683932e37db1f9",
            "cad57b63315746f79d2c8ecc0b4dcf30",
            "97d6c21a58a94e1ba4946789c9efa451",
            "8d0e7c9b85184b54a291f6fd8bcf5a50",
            "4cfe229ca1664515a15133fcc5519457",
            "beb261771e8640d8aab048e48da4ec47"
          ]
        }
      },
      "source": [
        "data_test_files = glob.glob(\"dataset_parsed/test/*.csv\")\n",
        "data_test = OpportunityDatasetParsed(data_test_files)\n",
        "\n",
        "i = 0\n",
        "for model in models:\n",
        "    with torch.no_grad():\n",
        "        #h = model.init_hidden()\n",
        "        dataloader_test = DataLoader(data_test, batch_size=batch_size,\n",
        "                        shuffle=False)\n",
        "        \n",
        "        label1_all = []\n",
        "        predicted1_all = []\n",
        "\n",
        "        for data, labels in log_progress(dataloader_test, name=\"Testing\"):\n",
        "            model.eval()\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            label1 = torch.reshape(labels[:, 0:1].long(), (-1,))\n",
        "            label1_all.extend(label1.tolist())\n",
        "\n",
        "            output1 = model(data)\n",
        "\n",
        "            _, predicted1 = torch.max(output1, 1)\n",
        "\n",
        "            predicted1_all.extend(predicted1.tolist())\n",
        "        \n",
        "        print(\"Grid: {}\".format(grids[i]))\n",
        "        i += 1\n",
        "        print(\"Accuracy: {}\".format(metrics.accuracy_score(label1_all, predicted1_all)))\n",
        "        print(\"F1 (micro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='micro')))\n",
        "        print(\"F1 (macro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='macro')))\n",
        "        print(\"F1 (weighted): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='weighted')))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99c64156779342b39bad78d14c13686a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(HTML(value=''), IntProgress(value=0, max=253)))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-7ff2613fb7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpredicted1_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-7b2f8de560b8>\u001b[0m in \u001b[0;36mlog_progress\u001b[0;34m(sequence, every, size, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevery\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-4b1d8199f8d5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# first 15 columns are for data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99AdHJYWWG12",
        "outputId": "13861c2a-c95d-4a48-a0a5-067bc7dd2239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "label1_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYcREY2Q1HCU",
        "outputId": "50e6b6dd-9315-481e-b8fe-041cf80cd163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "axs.plot(range(0, num_epochs), train_losses, label=\"train_loss\")\n",
        "axs.plot(range(0, num_epochs), val_losses, label=\"val_loss\")\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd78b49ce48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9XcjFoFNpz"
      },
      "source": [
        "test = torch.FloatTensor([[1, 2], [1, 2], [1, 2], [1, 2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQn14WzFd4J",
        "outputId": "982dbcee-0e6a-453b-cdd8-87887f667a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test.transpose(0, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PwjMDEhFpQB",
        "outputId": "9929a1d5-2d2c-4c8f-c03a-7b96dc36be51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "torch.randn(3, 5, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4448,  1.1153, -0.3726,  1.3726, -0.1775],\n",
              "        [ 0.3801,  0.0387, -1.7176,  0.6296,  1.6406],\n",
              "        [ 0.5300, -0.4268,  0.1901, -0.6905, -0.8405]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0nIQPMNXmYX",
        "outputId": "3916b5ab-0b75-4cd9-8316-34f1b0731ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.empty(3, dtype=torch.long).random_(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}