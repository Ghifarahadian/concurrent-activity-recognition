{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Log progress\n",
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )\n",
    "\n",
    "if IS_COLAB:\n",
    "    # using google colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    ROOT = os.path.join('/content', 'drive', 'My Drive',\n",
    "                        'concurrent-activity-recognition')\n",
    "    os.chdir(ROOT)\n",
    "else:\n",
    "    # using AWS\n",
    "    ROOT = os.path.join('/home', 'ubuntu', 'concurrent-activity-recognition')\n",
    "    os.chdir(ROOT)\n",
    "\n",
    "print(ROOT)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "#if False:\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset constant\n",
    "FEATURE_LENGTH = 36\n",
    "LABEL_LENGTH = 3\n",
    "FILE_LENGTH = 30\n",
    "DATASET_DIR = \"dataset_parsed_all_features_label0_label1\"\n",
    "LABEL_INDEX = 0\n",
    "LABEL_COUNT = 3\n",
    "\n",
    "class OpportunityDatasetParsed(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        self.filenames = filenames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        #print(filename)\n",
    "\n",
    "        df = pd.read_csv(filename, header=0)\n",
    "\n",
    "        # first FEATURE_LENGTH columns are for data\n",
    "        data = torch.FloatTensor(\n",
    "            df.iloc[:, :FEATURE_LENGTH].values.astype('float'))\n",
    "                \n",
    "        # last LABEL_LENGTH columns are for label\n",
    "        label = torch.FloatTensor(\n",
    "            df.iloc[FILE_LENGTH-1, FEATURE_LENGTH:(FEATURE_LENGTH+LABEL_LENGTH)].values.astype('float'))\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MODEL = \"CNNLSTM\"\n",
    "MODEL_NAME = \"CNNLSTM_label0_label1\"\n",
    "\n",
    "# grid search for CNNLSTM\n",
    "if USE_MODEL == \"CNNLSTM\":\n",
    "    conv1_outchs = [20]\n",
    "    conv1_sizes = [3]\n",
    "    conv2_outchs = [40]\n",
    "    conv2_sizes = [3]\n",
    "    lstm1_hs = [20]\n",
    "    learning_rates = [0.01]\n",
    "\n",
    "    grids = [(conv1_outch, conv1_size, conv2_outch,\n",
    "            conv2_size, lstm1_h, learning_rate)\n",
    "            for conv1_outch in conv1_outchs\n",
    "            for conv1_size in conv1_sizes\n",
    "            for conv2_outch in conv2_outchs\n",
    "            for conv2_size in conv2_sizes\n",
    "            for lstm1_h in lstm1_hs\n",
    "            for learning_rate in learning_rates\n",
    "            ]\n",
    "\n",
    "if USE_MODEL == \"CNN_Custom\":\n",
    "    grids = [1]\n",
    "\n",
    "print(\"Total grid parameters: \" + str(len(grids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameter\n",
    "num_epochs = 50\n",
    "batch_size = 8\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, grid):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        conv1_outch = grid[0]\n",
    "        conv1_size = grid[1]\n",
    "        conv1_outlen = FILE_LENGTH - (conv1_size - 1)\n",
    "        conv2_outch = grid[2]\n",
    "        conv2_size = grid[3]\n",
    "        conv2_outlen = conv1_outlen - (conv2_size - 1)\n",
    "        lstm1_h = grid[4]\n",
    "        self.lstm1_h = lstm1_h\n",
    "        lstm1_hlen = conv2_outlen\n",
    "        self.lstm1_hlen = lstm1_hlen\n",
    "        \n",
    "        # 2nd LSTM layer\n",
    "        self.lstm2_h = lstm1_h\n",
    "        lstm2_hlen = lstm1_hlen\n",
    "        self.lstm2_hlen = lstm2_hlen\n",
    "\n",
    "        self.conv1 = nn.Conv1d(FEATURE_LENGTH, conv1_outch, conv1_size)\n",
    "        self.conv2 = nn.Conv1d(conv1_outch, conv2_outch, conv2_size)\n",
    "        self.lstm1 = nn.LSTM(conv2_outch, lstm1_h)\n",
    "        self.fc1 = nn.Linear(lstm1_h*lstm1_hlen, 3)\n",
    "        \n",
    "        # 2nd LSTM layer\n",
    "        self.lstm2 = nn.LSTM(lstm1_h, self.lstm2_h)\n",
    "        self.fc2 = nn.Linear(lstm1_h*lstm1_hlen, 13)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.init_hidden()\n",
    "        batch_len = x.shape[0]\n",
    "        x.transpose_(1, 2)\n",
    "        x = F.relu(self.conv1(x), inplace=False)\n",
    "        x = F.relu(self.conv2(x), inplace=False)\n",
    "        x.transpose_(1, 2)\n",
    "        x1ini, _ = self.lstm1(x, h)\n",
    "        x1 = x1ini.reshape([batch_len, -1])\n",
    "        out1 = self.fc1(x1)\n",
    "        \n",
    "#         # first layer\n",
    "#         return out1\n",
    "        \n",
    "        # second layer\n",
    "        x2, _ = self.lstm2(x1ini, h)\n",
    "        x2 = x2.reshape([batch_len, -1])\n",
    "        out2 = self.fc2(x2)\n",
    "        return out1, out2\n",
    "\n",
    "    def init_hidden(self):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(1, self.lstm1_hlen,\n",
    "                             self.lstm1_h).zero_().to(device),\n",
    "                  weight.new(1, self.lstm1_hlen,\n",
    "                             self.lstm1_h).zero_().to(device))\n",
    "        return hidden\n",
    "\n",
    "class CNN_Custom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Custom, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 50, (1, 5))\n",
    "        self.pool1 = nn.MaxPool2d((1, 2))\n",
    "        self.conv2 = nn.Conv2d(50, 40, (1, 5))\n",
    "        self.pool2 = nn.MaxPool2d((1, 3))\n",
    "        self.conv3 = nn.Conv2d(40, 20, (1, 3))\n",
    "        self.fc1 = nn.Linear(FEATURE_LENGTH*20, LABEL_COUNT)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(20, 20, FEATURE_LENGTH, groups=20)\n",
    "        self.fc2 = nn.Linear(20, LABEL_COUNT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_len = x.shape[0]\n",
    "        x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
    "        x.transpose_(2, 3)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(x.shape)\n",
    "\n",
    "        # simple concatenation. It works better in the end\n",
    "        x = x.reshape([batch_len, -1])\n",
    "        x = self.fc1(x)\n",
    "\n",
    "#         # depth-wise convolution for parameter concatenation\n",
    "#         x = x.reshape([batch_len, 20, 36])\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         x = x.reshape([batch_len, -1])\n",
    "#         x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def make_train_step(model, loss_function, optimizer):\n",
    "    def train_step(data, labels):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        data = torch.reshape(data, (len(labels), -1, FEATURE_LENGTH))\n",
    "\n",
    "        label1 = torch.reshape(labels[:, LABEL_INDEX:LABEL_INDEX+1].long(), (-1,))\n",
    "        \n",
    "#         # for 1 label\n",
    "#         output1 = model(data)\n",
    "#         loss = loss_function(output1, label1)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # for 2 labels\n",
    "        output1, output2 = model(data)\n",
    "        \n",
    "        label2 = torch.reshape(labels[:, 1:1+1].long(), (-1,))\n",
    "        \n",
    "        loss = loss_function(output1, label1)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss_function(output2, label2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation, by using grid search/configured parameters\n",
    "LEARNING_RATE = 0.01\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "torch.manual_seed(69)\n",
    "models = []\n",
    "fig, axs = plt.subplots(1, figsize=(18, 4*1))\n",
    "i = 0\n",
    "for grid in grids:\n",
    "    if USE_MODEL == \"CNNLSTM\":\n",
    "        model = CNN_LSTM(grid).to(device)\n",
    "    elif USE_MODEL == \"CNN_Custom\":\n",
    "        model = CNN_Custom().to(device)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "    train_step = make_train_step(model, loss_function, optimizer)\n",
    "\n",
    "    data_train_files = glob.glob(DATASET_DIR + \"/train/*.csv\")\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    data_train = OpportunityDatasetParsed(data_train_files)\n",
    "    train_dataset, val_dataset = random_split(data_train,\n",
    "            [math.ceil(TRAIN_RATIO*len(data_train)), math.floor((1 - TRAIN_RATIO)*len(data_train))])\n",
    "\n",
    "    for epoch in log_progress(range(num_epochs), name=\"Epoch\"):\n",
    "        dataloader_train = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "        \n",
    "        train_losses_temp = []\n",
    "        for data, labels in dataloader_train:\n",
    "            loss = train_step(data, labels)\n",
    "            train_losses_temp.append(loss)\n",
    "\n",
    "        train_losses.append(np.mean(train_losses_temp))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dataloader_val = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "            \n",
    "            val_losses_temp = []\n",
    "            for data, labels in dataloader_val:\n",
    "                model.eval()\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "                label1 = torch.reshape(labels[:, LABEL_INDEX:LABEL_INDEX+1].long(), (-1,))\n",
    "                \n",
    "#                 # for 1 label\n",
    "#                 output1 = model(data)\n",
    "#                 val_loss = loss_function(output1, label1)\n",
    "#                 val_losses_temp.append(val_loss.item())\n",
    "                \n",
    "                # for 2 labels\n",
    "                output1, output2 = model(data)\n",
    "                label2 = torch.reshape(labels[:, 1:1+1].long(), (-1,))\n",
    "                val_loss1 = loss_function(output1, label1)\n",
    "                val_loss2 = loss_function(output2, label2)\n",
    "                val_loss_avg = (val_loss1.item() + val_loss2.item())/2\n",
    "                val_losses_temp.append(val_loss2.item())\n",
    "\n",
    "                \n",
    "            \n",
    "            val_losses.append(np.mean(val_losses_temp))\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    try:\n",
    "        axs[i].plot(range(0, num_epochs), train_losses, label=\"train_loss\")\n",
    "        axs[i].plot(range(0, num_epochs), val_losses, label=\"val_loss\")\n",
    "        axs[i].set_title(grid)\n",
    "    except:\n",
    "        axs.plot(range(0, num_epochs), train_losses, label=\"train_loss\")\n",
    "        axs.plot(range(0, num_epochs), val_losses, label=\"val_loss\")\n",
    "        axs.set_title(grid)\n",
    "    i += 1\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and save the model\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "data_test_files = glob.glob(DATASET_DIR + \"/test/*.csv\")\n",
    "data_test = OpportunityDatasetParsed(data_test_files)\n",
    "\n",
    "i = 0\n",
    "for model in models:\n",
    "    with torch.no_grad():\n",
    "        #h = model.init_hidden()\n",
    "        dataloader_test = DataLoader(data_test, batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "        \n",
    "        label1_all = []\n",
    "        predicted1_all = []\n",
    "\n",
    "        for data, labels in log_progress(dataloader_test, name=\"Testing\"):\n",
    "            model.eval()\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            label1 = torch.reshape(labels[:, LABEL_INDEX:LABEL_INDEX+1].long(), (-1,))\n",
    "            label1_all.extend(label1.tolist())\n",
    "\n",
    "            output1 = model(data)\n",
    "\n",
    "            _, predicted1 = torch.max(output1, 1)\n",
    "\n",
    "            predicted1_all.extend(predicted1.tolist())\n",
    "        \n",
    "        print(\"Grid: {}\".format(grids[i]))\n",
    "        print(\"Accuracy: {}\".format(metrics.accuracy_score(label1_all, predicted1_all)))\n",
    "        print(\"F1 (micro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='micro')))\n",
    "        print(\"F1 (macro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='macro')))\n",
    "        print(\"F1 (weighted): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='weighted')))\n",
    "\n",
    "    with open(\"models/\" + MODEL_NAME + \"_\" + datetime.now().strftime(\"%d%m%Y%H%M%S\") + \".p\", 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and test it, just to be sure\n",
    "loaded_model = pickle.load(open(\"models/CNN_Custom_label1_19112020084756.p\", 'rb'))\n",
    "\n",
    "data_test_files = glob.glob(\"dataset_parsed_all_features_label1\" + \"/test/*.csv\")\n",
    "data_test = OpportunityDatasetParsed(data_test_files)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataloader_test = DataLoader(data_test, batch_size=batch_size,\n",
    "                    shuffle=False)\n",
    "\n",
    "    label1_all = []\n",
    "    predicted1_all = []\n",
    "\n",
    "    for data, labels in log_progress(dataloader_test, name=\"Testing\"):\n",
    "        loaded_model.eval()\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        label1 = torch.reshape(labels[:, LABEL_INDEX:LABEL_INDEX+1].long(), (-1,))\n",
    "        label1_all.extend(label1.tolist())\n",
    "\n",
    "        output1 = loaded_model(data)\n",
    "\n",
    "        _, predicted1 = torch.max(output1, 1)\n",
    "\n",
    "        predicted1_all.extend(predicted1.tolist())\n",
    "\n",
    "    print(\"Accuracy: {}\".format(metrics.accuracy_score(label1_all, predicted1_all)))\n",
    "    print(\"F1 (micro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='micro')))\n",
    "    print(\"F1 (macro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='macro')))\n",
    "    print(\"F1 (weighted): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two models for prediction of label0 and label1\n",
    "import pickle\n",
    "loaded_model_label0 = pickle.load(open(\"models/CNN_Custom_label0_19112020090508.p\", 'rb'))\n",
    "loaded_model_label1 = pickle.load(open(\"models/CNN_Custom_label1_19112020090833.p\", 'rb'))\n",
    "\n",
    "data_test_files = glob.glob(\"dataset_parsed_few_features_label0_label1\" + \"/test/*.csv\")\n",
    "data_test = OpportunityDatasetParsed(data_test_files)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataloader_test = DataLoader(data_test, batch_size=batch_size,\n",
    "                    shuffle=False)\n",
    "\n",
    "    label0_all = []\n",
    "    predicted0_all = []\n",
    "    label1_all = []\n",
    "    predicted1_all = []\n",
    "\n",
    "    for data, labels in log_progress(dataloader_test, name=\"Testing\"):\n",
    "        loaded_model_label0.eval()\n",
    "        loaded_model_label1.eval()\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        label0 = torch.reshape(labels[:, 0:0+1].long(), (-1,))\n",
    "        label0_all.extend(label0.tolist())\n",
    "        \n",
    "        label1 = torch.reshape(labels[:, 1:1+1].long(), (-1,))\n",
    "        label1_all.extend(label1.tolist())\n",
    "\n",
    "        output0 = loaded_model_label0(data)\n",
    "        output1 = loaded_model_label1(data)\n",
    "\n",
    "        _, predicted0 = torch.max(output0, 1)\n",
    "        _, predicted1 = torch.max(output1, 1)\n",
    "\n",
    "        predicted0_all.extend(predicted0.tolist())\n",
    "        predicted1_all.extend(predicted1.tolist())\n",
    "\n",
    "    print(\"Label0:\")\n",
    "    print(\"Accuracy: {}\".format(metrics.accuracy_score(label0_all, predicted0_all)))\n",
    "    print(\"F1 (micro): {}\".format(metrics.f1_score(label0_all, predicted0_all, average='micro')))\n",
    "    print(\"F1 (macro): {}\".format(metrics.f1_score(label0_all, predicted0_all, average='macro')))\n",
    "    print(\"F1 (weighted): {}\".format(metrics.f1_score(label0_all, predicted0_all, average='weighted')))\n",
    "    \n",
    "    print(\"Label1:\")\n",
    "    print(\"Accuracy: {}\".format(metrics.accuracy_score(label1_all, predicted1_all)))\n",
    "    print(\"F1 (micro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='micro')))\n",
    "    print(\"F1 (macro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='macro')))\n",
    "    print(\"F1 (weighted): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for LSTM 2 labels\n",
    "data_test_files = glob.glob(DATASET_DIR + \"/test/*.csv\")\n",
    "data_test = OpportunityDatasetParsed(data_test_files)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dataloader_test = DataLoader(data_test, batch_size=batch_size,\n",
    "                    shuffle=False)\n",
    "\n",
    "    label0_all = []\n",
    "    predicted0_all = []\n",
    "    label1_all = []\n",
    "    predicted1_all = []\n",
    "\n",
    "    for data, labels in log_progress(dataloader_test, name=\"Testing\"):\n",
    "        model.eval()\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        label0 = torch.reshape(labels[:, 0:0+1].long(), (-1,))\n",
    "        label0_all.extend(label0.tolist())\n",
    "        \n",
    "        label1 = torch.reshape(labels[:, 1:1+1].long(), (-1,))\n",
    "        label1_all.extend(label1.tolist())\n",
    "\n",
    "        output0, output1 = model(data)\n",
    "\n",
    "        _, predicted0 = torch.max(output0, 1)\n",
    "        _, predicted1 = torch.max(output1, 1)\n",
    "\n",
    "        predicted0_all.extend(predicted0.tolist())\n",
    "        predicted1_all.extend(predicted1.tolist())\n",
    "\n",
    "    print(\"Label0:\")\n",
    "    print(\"Accuracy: {}\".format(metrics.accuracy_score(label0_all, predicted0_all)))\n",
    "    print(\"F1 (micro): {}\".format(metrics.f1_score(label0_all, predicted0_all, average='micro')))\n",
    "    print(\"F1 (macro): {}\".format(metrics.f1_score(label0_all, predicted0_all, average='macro')))\n",
    "    print(\"F1 (weighted): {}\".format(metrics.f1_score(label0_all, predicted0_all, average='weighted')))\n",
    "    \n",
    "    print(\"Label1:\")\n",
    "    print(\"Accuracy: {}\".format(metrics.accuracy_score(label1_all, predicted1_all)))\n",
    "    print(\"F1 (micro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='micro')))\n",
    "    print(\"F1 (macro): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='macro')))\n",
    "    print(\"F1 (weighted): {}\".format(metrics.f1_score(label1_all, predicted1_all, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_files = glob.glob(DATASET_DIR + \"/train/*.csv\")\n",
    "data_test_files = glob.glob(DATASET_DIR + \"/test/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
